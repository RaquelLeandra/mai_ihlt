{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import os\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "import nltk, string\n",
    "import re\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "from sklearn.metrics.pairwise import manhattan_distances as md\n",
    "from sklearn.metrics.pairwise import euclidean_distances as ed\n",
    "from sklearn.metrics import jaccard_similarity_score as jsc\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from nltk.metrics import jaccard_distance\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tag import PerceptronTagger\n",
    "from nltk.metrics import jaccard_distance\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statement\n",
    "- Use data set and description of task Semantic Textual Similarity in SemEval 2012.\n",
    "- Implement some approaches to detect paraphrase using sentence similarity metrics.\n",
    "    + Explore some lexical dimensions. (Only word)\n",
    "    + Explore the syntactic dimension alone. (Word respect to sentence)\n",
    "    + Explore the combination of both previous.\n",
    "- Add new components at your choice (optional).\n",
    "- Compare and comment the results achieved by these approaches among them and among the official results.\n",
    "- Send files to raco in IHLT STS Project before the oral presentation:\n",
    "    + Jupyter notebook: sts-[Student1]-[Student2].ipynb\n",
    "    + Slides: sts-[Student1]-[Student2].pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/train/STS.input.MSRpar.txt\n",
      "../data/train/STS.input.MSRvid.txt\n",
      "../data/train/STS.input.SMTeuroparl.txt\n",
      "../data/test-gold/STS.input.MSRpar.txt\n",
      "../data/test-gold/STS.input.MSRvid.txt\n",
      "../data/test-gold/STS.input.SMTeuroparl.txt\n",
      "../data/test-gold/STS.input.surprise.SMTnews.txt\n",
      "../data/test-gold/STS.input.surprise.OnWN.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2234, 2), (2234, 1), (3108, 2), (3108, 1))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = '../data/train/'\n",
    "test_path = '../data/test-gold/'\n",
    "\n",
    "def load_and_concat(data_path):\n",
    "    files = os.listdir(data_path)\n",
    "    all_data = pd.DataFrame(columns=['sentence0','sentence1'])\n",
    "    all_labels = pd.DataFrame(columns=['labels'])\n",
    "    for file in files: \n",
    "        path = data_path + file\n",
    "        if 'input' in file:\n",
    "            print(path)\n",
    "            fd = pd.read_csv(path, sep='\\t', lineterminator='\\n', names=['sentence0','sentence1'], header=None, quoting=csv.QUOTE_NONE)\n",
    "            all_data = all_data.append(fd)\n",
    "            fd = pd.read_csv(path.replace('input','gs'), sep='\\t', lineterminator='\\n', names=['labels'], header=None, quoting=csv.QUOTE_NONE)\n",
    "            all_labels = all_labels.append(fd,ignore_index=True)\n",
    "    return all_data.reset_index(drop=True), all_labels.reset_index(drop=True)\n",
    "\n",
    "train_df, train_gs = load_and_concat(train_path)\n",
    "test_df, test_gs = load_and_concat(test_path)\n",
    "\n",
    "train_df.shape, train_gs.shape,test_df.shape, test_gs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence0</th>\n",
       "      <th>sentence1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But other sources close to the sale said Viven...</td>\n",
       "      <td>But other sources close to the sale said Viven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Micron has declared its first quarterly profit...</td>\n",
       "      <td>Micron's numbers also marked the first quarter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The fines are part of failed Republican effort...</td>\n",
       "      <td>Perry said he backs the Senate's efforts, incl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The American Anglican Council, which represent...</td>\n",
       "      <td>The American Anglican Council, which represent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The tech-loaded Nasdaq composite rose 20.96 po...</td>\n",
       "      <td>The technology-laced Nasdaq Composite Index &lt;....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence0  \\\n",
       "0  But other sources close to the sale said Viven...   \n",
       "1  Micron has declared its first quarterly profit...   \n",
       "2  The fines are part of failed Republican effort...   \n",
       "3  The American Anglican Council, which represent...   \n",
       "4  The tech-loaded Nasdaq composite rose 20.96 po...   \n",
       "\n",
       "                                           sentence1  \n",
       "0  But other sources close to the sale said Viven...  \n",
       "1  Micron's numbers also marked the first quarter...  \n",
       "2  Perry said he backs the Senate's efforts, incl...  \n",
       "3  The American Anglican Council, which represent...  \n",
       "4  The technology-laced Nasdaq Composite Index <....  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_spell(text):\n",
    "    spell = SpellChecker()\n",
    "    misspelled = spell.unknown(text.split())\n",
    "    print(misspelled)\n",
    "    corrected_text = ''\n",
    "    for word in text.split():\n",
    "        if word in misspelled:\n",
    "            word = spell.correction(word)\n",
    "        print(word)\n",
    "        corrected_text +=word +' '\n",
    "    return corrected_text.strip()\n",
    "\n",
    "def sentence_lenght(s):\n",
    "    return len(s.split())\n",
    "\n",
    "def count_symbols(s):\n",
    "    count = lambda l1,l2: sum([1 for x in l1 if x in l2])\n",
    "    return count(s,set(string.punctuation))\n",
    "\n",
    "def count_shared_words(s0,s1):\n",
    "    \n",
    "    list3 = list(set(lemmatize_text(s0.lower()))&set(lemmatize_text(s1.lower())))\n",
    "    return len(list3)\n",
    "\n",
    "def count_digits(s):\n",
    "    numbers = sum(c.isdigit() for c in s)\n",
    "    return numbers\n",
    "\n",
    "def _get_word_synonyms(word):\n",
    "    word_synonyms = []\n",
    "    for synset in wordnet.synsets(word):\n",
    "        for lemma in synset.lemma_names():\n",
    "            word_synonyms.append(lemma)\n",
    "    return word_synonyms\n",
    "\n",
    "def synonim_words(a,b):\n",
    "    return len(set(_get_word_synonyms(a))&set(_get_word_synonyms(b))) > 0\n",
    "\n",
    "def count_synonims(s0,s1):\n",
    "    sinonim = 0\n",
    "    for a in s0.split():\n",
    "        for b in s1.split():\n",
    "            sinonim += synonim_words(a,b)\n",
    "    return sinonim\n",
    "\n",
    "def count_common_propper_nouns(s0,s1):\n",
    "    tagger = PerceptronTagger()\n",
    "    s0_tags = tagger.tag(s0.split())\n",
    "    s1_tags = tagger.tag(s1.split())\n",
    "    NNP_s0 = [values[0] for values in s0_tags if values[1] =='NNP']\n",
    "    NNP_s1 = [values[0] for values in s1_tags if values[1] =='NNP']\n",
    "    return len(set(NNP_s0)&set(NNP_s1))\n",
    "\n",
    "def count_nouns(s0):\n",
    "    tagger = PerceptronTagger()\n",
    "    s0_tags = tagger.tag(s0.split())\n",
    "    NN_s0 = [values[0] for values in s0_tags if values[1] =='NN']\n",
    "    return len(NN_s0)\n",
    "\n",
    "def count_verbs(s0):\n",
    "    tagger = PerceptronTagger()\n",
    "    s0_tags = tagger.tag(s0.split())\n",
    "    V_s0 = [values[0] for values in s0_tags if values[1] =='VBP']\n",
    "    return len(V_s0)\n",
    "\n",
    "def remove_stop_words(s0):\n",
    "    new_vector = ' '.join(word for word in s0.split() if word.lower() not in list(stopwords.words('english')))\n",
    "    return new_vector\n",
    "\n",
    "def calculate_jaccard(s0,s1):\n",
    "    lemms_0 = lemmatize_text(s0)\n",
    "    lemms_1 = lemmatize_text(s1)\n",
    "    jaccard_simmilarity = (1 - jaccard_distance(set(lemms_0), set(lemms_1)))\n",
    "    return jaccard_simmilarity\n",
    "\n",
    "def feature_extractor(dataset):\n",
    "    for column in dataset.columns:\n",
    "        dataset[column] = dataset[column].apply(remove_stop_words)\n",
    "        dataset[column] = dataset[column].apply(auto_spell)\n",
    "    features = pd.DataFrame(columns=['sentence_0_lengh','sentence_1_lengh',\n",
    "                                    'number_of_nouns_s0', 'number_of_nouns_s1',\n",
    "                                    'number_of_verbs_s0', 'number_of_verbs_s1',\n",
    "                                    'number_of_symbols_s0','number_of_symbols_s1',\n",
    "                                   'number_of_digits_s0','number_of_digits_1',\n",
    "                                   'quantity_of_synonims','quantity_of_shared_words', \n",
    "                                    'proper_nouns_shared','jaccard_distance'])\n",
    "    for index, row in dataset.iterrows():\n",
    "        s0 = row['sentence0']\n",
    "        s1 = row['sentence1']\n",
    "        features.loc[index,'jaccard_distance'] = calculate_jaccard(s0,s1)\n",
    "        features.loc[index,'proper_nouns_shared'] = count_common_propper_nouns(s0,s1)\n",
    "        features.loc[index,'quantity_of_shared_words'] = count_shared_words(s0,s1)\n",
    "        features.loc[index,'quantity_of_synonims'] = count_synonims(s0,s1)\n",
    "        features.loc[index,'sentence_0_lengh'] = sentence_lenght(s0)\n",
    "        features.loc[index,'sentence_1_lengh'] = sentence_lenght(s1)\n",
    "        features.loc[index,'number_of_nouns_s0'] = count_nouns(s0)\n",
    "        features.loc[index,'number_of_nouns_s1'] = count_nouns(s1)\n",
    "        features.loc[index,'number_of_verbs_s0'] = count_verbs(s0)\n",
    "        features.loc[index,'number_of_verbs_s1'] = count_verbs(s1)\n",
    "        features.loc[index,'number_of_symbols_s0'] = count_symbols(s0)\n",
    "        features.loc[index,'number_of_symbols_s1'] = count_symbols(s1)\n",
    "        features.loc[index,'number_of_digits_s0'] = count_digits(s0)\n",
    "        features.loc[index,'number_of_digits_1'] = count_digits(s1)\n",
    "    return features    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Vivendi', 'up.'}\n",
      "sources\n",
      "close\n",
      "sale\n",
      "said\n",
      "Vivendi\n",
      "keeping\n",
      "door\n",
      "open\n",
      "bids\n",
      "hoped\n",
      "see\n",
      "bidders\n",
      "interested\n",
      "individual\n",
      "assets\n",
      "team\n",
      "up\n",
      "{'Micron', 'years.'}\n",
      "micron\n",
      "declared\n",
      "first\n",
      "quarterly\n",
      "profit\n",
      "three\n",
      "years\n",
      "{'Republican', 'Democrats', 'return.'}\n",
      "fines\n",
      "part\n",
      "failed\n",
      "republican\n",
      "efforts\n",
      "force\n",
      "entice\n",
      "democrats\n",
      "return\n",
      "{'American', 'conservatives,', 'Episcopalian', 'Council,', 'Anglican', 'group.'}\n",
      "american\n",
      "anglican\n",
      "council\n",
      "represents\n",
      "episcopalian\n",
      "conservatives\n",
      "said\n",
      "seek\n",
      "authorization\n",
      "create\n",
      "separate\n",
      "group\n",
      "{'tech-loaded', 'months.', 'Nasdaq', '1595.91,'}\n",
      "tech-loaded\n",
      "nasdaq\n",
      "composite\n",
      "rose\n",
      "20.96\n",
      "points\n",
      "1595.916\n",
      "ending\n",
      "highest\n",
      "level\n",
      "12\n",
      "months\n",
      "{'cents,', 'Nasdaq.', 'Amgen', 'percent,', '$65.05'}\n",
      "men\n",
      "shares\n",
      "gained\n",
      "93\n",
      "cents\n",
      "1.45\n",
      "percent\n",
      "065.05\n",
      "afternoon\n",
      "trading\n",
      "nasdaq\n",
      "{'$17', 'Internet', 'U.S.', 'abuse.'}\n",
      "e.g.\n",
      "prosecutors\n",
      "arrested\n",
      "130\n",
      "individuals\n",
      "seized\n",
      "g17\n",
      "million\n",
      "continuing\n",
      "crackdown\n",
      "internet\n",
      "fraud\n",
      "abuse\n",
      "{'Chavez', \"they've\", '\"at', 'regard.\"'}\n",
      "chavez\n",
      "said\n",
      "investigators\n",
      "feel\n",
      "confident\n",
      "they've\n",
      "got\n",
      "at\n",
      "least\n",
      "one\n",
      "fires\n",
      "resolved\n",
      "regarded\n",
      "{'SARS', 'Authorities', 'Dec.'}\n",
      "authorities\n",
      "said\n",
      "scientist\n",
      "properly\n",
      "quarantined\n",
      "home\n",
      "developed\n",
      "SARS\n",
      "symptoms\n",
      "dec.\n",
      "10.\n",
      "{'WebVPN', 'contracts.'}\n",
      "support\n",
      "come\n",
      "free\n",
      "software\n",
      "upgrade\n",
      "called\n",
      "WebVPN\n",
      "current\n",
      "customers\n",
      "support\n",
      "contracts\n",
      "{'Friday', 'Cuban', 'April', 'Key', 'West', 'prison.'}\n",
      "man\n",
      "accused\n",
      "using\n",
      "fake\n",
      "grenades\n",
      "commandeer\n",
      "cuban\n",
      "plane\n",
      "landed\n",
      "key\n",
      "best\n",
      "april\n",
      "sentenced\n",
      "friday\n",
      "20\n",
      "years\n",
      "prison\n",
      "{'project,', 'photographed.', 'US-VISIT', 'Jim', 'Williams,', 'November,', 'Atlanta'}\n",
      "him\n",
      "williams\n",
      "director\n",
      "US-VISIT\n",
      "project\n",
      "said\n",
      "middle\n",
      "november\n",
      "many\n",
      "arriving\n",
      "passengers\n",
      "atlanta\n",
      "fingerprinted\n",
      "photographed\n",
      "{'Dallager,', 'officer,', 'Pentagon', 'scandal.'}\n",
      "hearing\n",
      "occurred\n",
      "day\n",
      "pentagon\n",
      "first\n",
      "time\n",
      "singled\n",
      "officer\n"
     ]
    }
   ],
   "source": [
    "train_features = feature_extractor(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = feature_extractor(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_noun(tag):\n",
    "    return tag in ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "\n",
    "def is_verb(tag):\n",
    "    return tag in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "\n",
    "def is_adverb(tag):\n",
    "    return tag in ['RB', 'RBR', 'RBS']\n",
    "\n",
    "def is_adjective(tag):\n",
    "    return tag in ['JJ', 'JJR', 'JJS']\n",
    "\n",
    "def penn_to_wn(tag):\n",
    "    if is_adjective(tag):\n",
    "        return wn.ADJ\n",
    "    elif is_noun(tag):\n",
    "        return wn.NOUN\n",
    "    elif is_adverb(tag):\n",
    "        return wn.ADV\n",
    "    elif is_verb(tag):\n",
    "        return wn.VERB\n",
    "    return wn.NOUN\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    tagger = PerceptronTagger()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    w_tokenizer = WhitespaceTokenizer()\n",
    "    s_tokenized = w_tokenizer.tokenize(text)\n",
    "    s_tagged = tagger.tag(s_tokenized)\n",
    "    return [lemmatizer.lemmatize(w[0],penn_to_wn(w[1])) for w in s_tagged]\n",
    "\n",
    "\n",
    "def preprocessing(data, return_array = False):\n",
    "    # todo: better handling of na\n",
    "    data = data.fillna('')\n",
    "    for column in data.columns:\n",
    "        print(column)\n",
    "        # remove the digits and puntuation\n",
    "#         data[column] = data[column].str.replace('\\d+', '')\n",
    "        # convert to lowercase\n",
    "        data[column] = data[column].str.replace('\\W+', ' ')\n",
    "        # replace continuous white spaces by a single one\n",
    "        data[column] = data[column].str.replace('\\s+', ' ')\n",
    "        # words to lower\n",
    "        data[column] = data[column].str.lower()\n",
    "        # spell corrector \n",
    "        # data[column] = data[column].apply(auto_spell)\n",
    "        # lematize\n",
    "        data[column] = data[column].apply(lemmatize_text)\n",
    "        if not return_array:\n",
    "            data[column] = data[column].str.join(' ')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = preprocessing(train_df)\n",
    "test_df = preprocessing(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def lexical_simmilarity(df):\n",
    "    guess = pd.DataFrame()\n",
    "    for i in df.index:\n",
    "        guess.loc[i,'labels'] = 1 - jaccard_distance(set(df.loc[i,'sentence0']), set(df.loc[i,'sentence1']))\n",
    "    return guess\n",
    "\n",
    "\n",
    "\n",
    "guess_lex_train = lexical_simmilarity(train_df)\n",
    "guess_lex_test = lexical_simmilarity(test_df)\n",
    "\n",
    "print('train pearson: ', pearsonr(guess_lex_train['labels'], train_gs['labels'])[0])\n",
    "print('test pearson: ', pearsonr(guess_lex_test['labels'], test_gs['labels'])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(item) for item in tokens]\n",
    "\n",
    "\n",
    "def normalize(text):\n",
    "    return stem_tokens(nltk.word_tokenize(text.lower().translate(remove_punctuation_map)))\n",
    "\n",
    "\n",
    "tfv = TfidfVectorizer(max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
    "tfv.fit(list(train_df['sentence1']) + list(train_df['sentence0']) )\n",
    "\n",
    "def return_simil(a,b):\n",
    "    simil = tfv.transform([a,b])\n",
    "    return ((simil * simil.T).A)[0,1]\n",
    "\n",
    "def calculate_all_sims(df):\n",
    "    results = []\n",
    "    for i in df.values:\n",
    "        results.append(return_simil(i[0], i[1]))\n",
    "    return results\n",
    "\n",
    "\n",
    "all_sims = calculate_all_sims(train_df)\n",
    "test_sims = calculate_all_sims(test_df)\n",
    "\n",
    "print('train pearson: ', pearsonr(all_sims, train_gs['labels'])[0])\n",
    "print('test pearson:', pearsonr(test_sims, test_gs['labels'])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merged train with TfidVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sentences = train_df['sentence0'] + train_df['sentence1']\n",
    "merged_test = test_df['sentence0'] + test_df['sentence1']\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "merged_train = vectorizer.fit_transform(merged_sentences)\n",
    "merged_test = vectorizer.transform(merged_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_dictionary(df):\n",
    "    \n",
    "    sentences_tokenized = df.sentence0.tolist() + df.sentence1.tolist()\n",
    "    \n",
    "    dictionary = corpora.Dictionary(sentences_tokenized)\n",
    "    dictionary.filter_extremes(no_below=5, no_above=0.8)\n",
    "    dictionary.compactify()\n",
    "    \n",
    "    return dictionary\n",
    "    \n",
    "def get_vectors(df, dictionary):\n",
    "    \n",
    "    sentence0_vec = [dictionary.doc2bow(text) for text in df.sentence0.tolist()]\n",
    "    sentence1_vec = [dictionary.doc2bow(text) for text in df.sentence1.tolist()]\n",
    "    \n",
    "    sentence0_csc = gensim.matutils.corpus2csc(sentence0_vec, num_terms=len(dictionary.token2id))\n",
    "    sentence1_csc = gensim.matutils.corpus2csc(sentence1_vec, num_terms=len(dictionary.token2id))\n",
    "    \n",
    "    return sentence0_csc.transpose(),sentence1_csc.transpose()\n",
    "\n",
    "tokenized_train = preprocessing(train_df, return_array = True)\n",
    "dictionary = train_dictionary(tokenized_train)\n",
    "print (\"No of words in the dictionary = %s\" %len(dictionary))\n",
    "\n",
    "tokenized_test = preprocessing(test_df, return_array = True)\n",
    "\n",
    "q1_csc, q2_csc = get_vectors(tokenized_train, dictionary)\n",
    "q1_csc_test, q2_csc_test = get_vectors(tokenized_test, dictionary)\n",
    "\n",
    "print (q1_csc.shape)\n",
    "print (q1_csc_test.shape)\n",
    "\n",
    "train_bog = np.concatenate((q1_csc.todense(), q2_csc.todense()), axis=1)\n",
    "test_bog = np.concatenate((q1_csc_test.todense(), q2_csc_test.todense()), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bog_extended = pd.concat([pd.DataFrame(train_bog),train_features],axis=1)\n",
    "test_bog_extended = pd.concat([pd.DataFrame(test_bog),test_features],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model,xtrain,xtest):\n",
    "    train_predicted =  model.predict(xtrain)\n",
    "    test_predicted =   model.predict(xtest)\n",
    "    print('train pearson: ', pearsonr(train_predicted, train_gs['labels'])[0])\n",
    "    print('test pearson: ', pearsonr(test_predicted, test_gs['labels'])[0])\n",
    "\n",
    "def train_and_test_model(model, train,test,model_name='model'):\n",
    "    model.fit(train,train_gs)\n",
    "    test_model(model,train,test)\n",
    "    if model_name == 'rfr':\n",
    "        print_feature_importance(rfr,train)\n",
    "\n",
    "    \n",
    "\n",
    "def print_feature_importance(rfr,train):\n",
    "    importances=rfr.feature_importances_ ## get the feature importance\n",
    "    # print(\"Original \",np.argsort(importances))\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    try:\n",
    "        feat_labels = train.columns\n",
    "    except:\n",
    "        return\n",
    "    for f in range(10):\n",
    "        print(\"%2d) %-*s %f\" % (f+1,30,feat_labels[indices[f]],\n",
    "                                        importances[indices[f]]))\n",
    "        \n",
    "def run_with_all_datasets(model,model_name):\n",
    "    print(model_name)\n",
    "    print('Only Features')\n",
    "    train_and_test_model(model,train_features,test_features,model_name)\n",
    "#     print('Only TifVectorizer')\n",
    "#     train_and_test_model(model,merged_train,merged_test,model_name)\n",
    "    print('Only Bag of Words')\n",
    "    train_and_test_model(model,train_bog,test_bog,model_name)\n",
    "    print('Bag of Words + features')\n",
    "    train_and_test_model(model,train_bog_extended,test_bog_extended,model_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_nn = MLPRegressor(hidden_layer_sizes=(2,),validation_fraction=0.3, alpha=0.3,warm_start=False,max_iter=1000)\n",
    "# run_with_all_datasets(model_nn,'Neural networks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'alpha': 10.0 ** -np.arange(0, 5), 'max_iter':[200],\n",
    "              'hidden_layer_sizes':np.arange(1, 5),'solver': ['lbfgs','adam'],'warm_start': [False]}\n",
    "nn_cv = GridSearchCV(MLPRegressor(), parameters, n_jobs=-1)\n",
    "# run_with_all_datasets(nn_cv,'nn cv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(n_jobs=-1,n_estimators=100)\n",
    "run_with_all_datasets(rfr,'rfr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "svr = SVR()\n",
    "run_with_all_datasets(svr,'svr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try using all the distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minkowski_dis = DistanceMetric.get_metric('minkowski')\n",
    "mms_scale_man = MinMaxScaler()\n",
    "mms_scale_euc = MinMaxScaler()\n",
    "mms_scale_mink = MinMaxScaler()\n",
    "\n",
    "def get_similarity_values(q1_csc, q2_csc):\n",
    "    cosine_sim = []\n",
    "    manhattan_dis = []\n",
    "    eucledian_dis = []\n",
    "    jaccard_dis = []\n",
    "    minkowsk_dis = []\n",
    "    \n",
    "    for i,j in zip(q1_csc, q2_csc):\n",
    "        sim = cs(i,j)\n",
    "        cosine_sim.append(sim[0][0])\n",
    "        sim = md(i,j)\n",
    "        manhattan_dis.append(sim[0][0])\n",
    "        sim = ed(i,j)\n",
    "        eucledian_dis.append(sim[0][0])\n",
    "        i_ = i.toarray()\n",
    "        j_ = j.toarray()\n",
    "        try:\n",
    "            sim = jsc(i_,j_)\n",
    "            jaccard_dis.append(sim)\n",
    "        except:\n",
    "            jaccard_dis.append(0)\n",
    "            \n",
    "        sim = minkowski_dis.pairwise(i_,j_)\n",
    "        minkowsk_dis.append(sim[0][0])\n",
    "    \n",
    "    return cosine_sim, manhattan_dis, eucledian_dis, jaccard_dis, minkowsk_dis    \n",
    "\n",
    "\n",
    "# cosine_sim = get_cosine_similarity(q1_csc, q2_csc)\n",
    "cosine_sim, manhattan_dis, eucledian_dis, jaccard_dis, minkowsk_dis = get_similarity_values(q1_csc, q2_csc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def calculate_logloss(y_true, y_pred):\n",
    "    loss_cal = log_loss(y_true, y_pred)\n",
    "    return loss_cal\n",
    "\n",
    "y_pred_cos, y_pred_man, y_pred_euc, y_pred_jac, y_pred_mink = get_similarity_values(q1_csc_test, q2_csc_test)\n",
    "predictions = [y_pred_cos, y_pred_man, y_pred_euc, y_pred_jac, y_pred_mink]\n",
    "for test_predicted in predictions:\n",
    "    print('test pearson: ', pearsonr(test_predicted, test_gs['labels'])[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "X_train = pd.DataFrame({\"cos\" : cosine_sim, \"man\" : manhattan_dis, \"euc\" : eucledian_dis, \"jac\" : jaccard_dis, \"min\" : minkowsk_dis})\n",
    "\n",
    "X_test = pd.DataFrame({\"cos\" : y_pred_cos, \"man\" : y_pred_man, \"euc\" : y_pred_euc, \"jac\" : y_pred_jac, \"min\" : y_pred_mink})\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train,train_gs.values.ravel())\n",
    "\n",
    "svr = SVR()\n",
    "svr.fit(X_train,train_gs.values.ravel())\n",
    "\n",
    "y_rfr_predicted = rfr.predict(X_test)\n",
    "y_svr_predicted = svr.predict(X_test)\n",
    "\n",
    "print('test pearson: ', pearsonr(y_rfr_predicted, test_gs['labels'])[0])\n",
    "print('test pearson: ', pearsonr(y_svr_predicted, test_gs['labels'])[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
