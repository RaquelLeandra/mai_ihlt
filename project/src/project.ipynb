{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import os\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "import nltk, string\n",
    "import re\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "from sklearn.metrics.pairwise import manhattan_distances as md\n",
    "from sklearn.metrics.pairwise import euclidean_distances as ed\n",
    "from sklearn.metrics import jaccard_similarity_score as jsc\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from nltk.metrics import jaccard_distance\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tag import PerceptronTagger\n",
    "from nltk.metrics import jaccard_distance \n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statement\n",
    "- Use data set and description of task Semantic Textual Similarity in SemEval 2012.\n",
    "- Implement some approaches to detect paraphrase using sentence similarity metrics.\n",
    "    + Explore some lexical dimensions. (Only word)\n",
    "    + Explore the syntactic dimension alone. (Word respect to sentence)\n",
    "    + Explore the combination of both previous.\n",
    "- Add new components at your choice (optional).\n",
    "- Compare and comment the results achieved by these approaches among them and among the official results.\n",
    "- Send files to raco in IHLT STS Project before the oral presentation:\n",
    "    + Jupyter notebook: sts-[Student1]-[Student2].ipynb\n",
    "    + Slides: sts-[Student1]-[Student2].pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/train/STS.input.MSRpar.txt\n",
      "../data/train/STS.input.MSRvid.txt\n",
      "../data/train/STS.input.SMTeuroparl.txt\n",
      "../data/test-gold/STS.input.MSRpar.txt\n",
      "../data/test-gold/STS.input.MSRvid.txt\n",
      "../data/test-gold/STS.input.SMTeuroparl.txt\n",
      "../data/test-gold/STS.input.surprise.OnWN.txt\n",
      "../data/test-gold/STS.input.surprise.SMTnews.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2234, 2), (2234, 1), (3108, 2), (3108, 1))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = '../data/train/'\n",
    "test_path = '../data/test-gold/'\n",
    "\n",
    "def load_and_concat(data_path):\n",
    "    files = os.listdir(data_path)\n",
    "    all_data = pd.DataFrame(columns=['sentence0','sentence1'])\n",
    "    all_labels = pd.DataFrame(columns=['labels'])\n",
    "    for file in files: \n",
    "        path = data_path + file\n",
    "        if 'input' in file:\n",
    "            print(path)\n",
    "            fd = pd.read_csv(path, sep='\\t', lineterminator='\\n', names=['sentence0','sentence1'], header=None, quoting=csv.QUOTE_NONE)\n",
    "            all_data = all_data.append(fd)\n",
    "            fd = pd.read_csv(path.replace('input','gs'), sep='\\t', lineterminator='\\n', names=['labels'], header=None, quoting=csv.QUOTE_NONE)\n",
    "            all_labels = all_labels.append(fd,ignore_index=True)\n",
    "    return all_data.reset_index(drop=True), all_labels.reset_index(drop=True)\n",
    "\n",
    "train_df, train_gs = load_and_concat(train_path)\n",
    "test_df, test_gs = load_and_concat(test_path)\n",
    "\n",
    "train_df.shape, train_gs.shape,test_df.shape, test_gs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence0</th>\n",
       "      <th>sentence1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But other sources close to the sale said Viven...</td>\n",
       "      <td>But other sources close to the sale said Viven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Micron has declared its first quarterly profit...</td>\n",
       "      <td>Micron's numbers also marked the first quarter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The fines are part of failed Republican effort...</td>\n",
       "      <td>Perry said he backs the Senate's efforts, incl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The American Anglican Council, which represent...</td>\n",
       "      <td>The American Anglican Council, which represent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The tech-loaded Nasdaq composite rose 20.96 po...</td>\n",
       "      <td>The technology-laced Nasdaq Composite Index &lt;....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence0  \\\n",
       "0  But other sources close to the sale said Viven...   \n",
       "1  Micron has declared its first quarterly profit...   \n",
       "2  The fines are part of failed Republican effort...   \n",
       "3  The American Anglican Council, which represent...   \n",
       "4  The tech-loaded Nasdaq composite rose 20.96 po...   \n",
       "\n",
       "                                           sentence1  \n",
       "0  But other sources close to the sale said Viven...  \n",
       "1  Micron's numbers also marked the first quarter...  \n",
       "2  Perry said he backs the Senate's efforts, incl...  \n",
       "3  The American Anglican Council, which represent...  \n",
       "4  The technology-laced Nasdaq Composite Index <....  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_spell(text):\n",
    "    spell = SpellChecker()\n",
    "    misspelled = spell.unknown(text.split())\n",
    "    tagger = PerceptronTagger()\n",
    "    tagged_text = tagger.tag(text)\n",
    "#     print(misspelled)\n",
    "    corrected_text = ''\n",
    "    for i, word in enumerate(text.split()):\n",
    "        if word in misspelled:\n",
    "            tag = tagged_text[i][1]\n",
    "            if tag != 'NNP':\n",
    "                word = spell.correction(word)\n",
    "        corrected_text +=word +' '\n",
    "    return corrected_text.strip()\n",
    "\n",
    "def sentence_lenght(s):\n",
    "    return len(s.split())\n",
    "\n",
    "def count_symbols(s):\n",
    "    count = lambda l1,l2: sum([1 for x in l1 if x in l2])\n",
    "    return count(s,set(string.punctuation))\n",
    "\n",
    "def count_shared_words(s0,s1):\n",
    "    \n",
    "    list3 = list(set(lemmatize_text(s0.lower()))&set(lemmatize_text(s1.lower())))\n",
    "    return len(list3)\n",
    "\n",
    "def count_digits(s):\n",
    "    numbers = sum(c.isdigit() for c in s)\n",
    "    return numbers\n",
    "\n",
    "def _get_word_synonyms(word):\n",
    "    word_synonyms = []\n",
    "    for synset in wn.synsets(word):\n",
    "        for lemma in synset.lemma_names():\n",
    "            word_synonyms.append(lemma)\n",
    "    return word_synonyms\n",
    "\n",
    "def synonim_words(a,b):\n",
    "    return len(set(_get_word_synonyms(a))&set(_get_word_synonyms(b))) > 0\n",
    "\n",
    "def count_synonims(s0,s1):\n",
    "    sinonim = 0\n",
    "    for a in s0.split():\n",
    "        for b in s1.split():\n",
    "            sinonim += synonim_words(a,b)\n",
    "    return sinonim\n",
    "\n",
    "def count_common_propper_nouns(s0,s1):\n",
    "    tagger = PerceptronTagger()\n",
    "    s0_tags = tagger.tag(s0.split())\n",
    "    s1_tags = tagger.tag(s1.split())\n",
    "    NNP_s0 = [values[0] for values in s0_tags if values[1] =='NNP']\n",
    "    NNP_s1 = [values[0] for values in s1_tags if values[1] =='NNP']\n",
    "    return len(set(NNP_s0)&set(NNP_s1))\n",
    "\n",
    "def count_nouns(s0):\n",
    "    tagger = PerceptronTagger()\n",
    "    s0_tags = tagger.tag(s0.split())\n",
    "    NN_s0 = [values[0] for values in s0_tags if values[1] =='NN']\n",
    "    return len(NN_s0)\n",
    "\n",
    "def count_verbs(s0):\n",
    "    tagger = PerceptronTagger()\n",
    "    s0_tags = tagger.tag(s0.split())\n",
    "    V_s0 = [values[0] for values in s0_tags if values[1] =='VBP']\n",
    "    return len(V_s0)\n",
    "\n",
    "def remove_stop_words(s0):\n",
    "    new_vector = ' '.join(word for word in s0.split() if word.lower() not in list(stopwords.words('english')))\n",
    "    return new_vector\n",
    "\n",
    "def calculate_jaccard(s0,s1):\n",
    "    lemms_0 = [a for  a in lemmatize_text(s0) if a]\n",
    "    lemms_1 = [a for  a in lemmatize_text(s1) if a]\n",
    "    \n",
    "    jaccard_simmilarity = (1 - jaccard_distance(set(lemms_0), set(lemms_1)))\n",
    "    return jaccard_simmilarity\n",
    "\n",
    "def penn_to_wn(tag):\n",
    "    \"\"\" Convert between a Penn Treebank tag to a simplified Wordnet tag \"\"\"\n",
    "    if tag.startswith('N'):\n",
    "        return 'n'\n",
    " \n",
    "    if tag.startswith('V'):\n",
    "        return 'v'\n",
    " \n",
    "    if tag.startswith('J'):\n",
    "        return 'a'\n",
    " \n",
    "    if tag.startswith('R'):\n",
    "        return 'r'\n",
    "    return 'n'\n",
    " \n",
    "def tagged_to_synset(word, tag):\n",
    "    wn_tag = penn_to_wn(tag)\n",
    "    if wn_tag is None:\n",
    "        return None\n",
    "    try:\n",
    "        return wn.synsets(word, wn_tag)[0]\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def sentence_similarity(sentence1, sentence2,similarity=wn.path_similarity):\n",
    "    \"\"\" compute the sentence similarity using Wordnet \"\"\"\n",
    "    # Tokenize and tag\n",
    "    sentence1 = pos_tag(lemmatize_text(sentence1))\n",
    "    sentence2 = pos_tag(lemmatize_text(sentence2))\n",
    " \n",
    "    # Get the synsets for the tagged words\n",
    "    synsets1 = [tagged_to_synset(*tagged_word) for tagged_word in sentence1]\n",
    "    synsets2 = [tagged_to_synset(*tagged_word) for tagged_word in sentence2]\n",
    " \n",
    "    # Filter out the Nones\n",
    "    synsets1 = [ss for ss in synsets1 if ss]\n",
    "    synsets2 = [ss for ss in synsets2 if ss]\n",
    "\n",
    "    score, count = 0.0, 0\n",
    " \n",
    "    # For each word in the first sentence\n",
    "    for synset in synsets1:\n",
    "        # Get the similarity value of the most similar word in the other sentence\n",
    "        similarities = [similarity(synset,ss) for ss in synsets2 if similarity(synset,ss) ]\n",
    "        try:\n",
    "            best_score = max(similarities)\n",
    "        except:\n",
    "            best_score = 0\n",
    "        # Check that the similarity could have been computed\n",
    "        if best_score is not None:\n",
    "            score += best_score\n",
    "            count += 1\n",
    " \n",
    "    # Average the values\n",
    "    try:\n",
    "        score /= count\n",
    "    except:\n",
    "        score = 0\n",
    "    return score\n",
    "\n",
    "def feature_extractor(dataset):\n",
    "    for column in dataset.columns:\n",
    "        dataset[column] = dataset[column].apply(remove_stop_words)\n",
    "        dataset[column] = dataset[column].str.replace('\\d+', '')\n",
    "#         dataset[column] = dataset[column].apply(auto_spell)\n",
    "    features = pd.DataFrame(columns=['sentence_0_lengh','sentence_1_lengh',\n",
    "                                    'number_of_nouns_s0', 'number_of_nouns_s1',\n",
    "                                    'number_of_verbs_s0', 'number_of_verbs_s1',\n",
    "                                    'number_of_symbols_s0','number_of_symbols_s1',\n",
    "                                   'number_of_digits_s0','number_of_digits_1',\n",
    "                                   'quantity_of_synonims','quantity_of_shared_words', \n",
    "                                    'proper_nouns_shared','jaccard_distance','path_similarity',\n",
    "                                    'wup_similarity'])\n",
    "    for index, row in dataset.iterrows():\n",
    "        s0 = row['sentence0']\n",
    "        s1 = row['sentence1']\n",
    "        features.loc[index,'jaccard_distance'] = calculate_jaccard(s0,s1)\n",
    "        features.loc[index,'path_similarity'] = sentence_similarity(s0,s1,wn.path_similarity)\n",
    "        features.loc[index,'wup_similarity'] = sentence_similarity(s0,s1,wn.wup_similarity)\n",
    "        features.loc[index,'proper_nouns_shared'] = count_common_propper_nouns(s0,s1)\n",
    "        features.loc[index,'quantity_of_shared_words'] = count_shared_words(s0,s1)\n",
    "        features.loc[index,'quantity_of_synonims'] = count_synonims(s0,s1)\n",
    "        features.loc[index,'sentence_0_lengh'] = sentence_lenght(s0)\n",
    "        features.loc[index,'sentence_1_lengh'] = sentence_lenght(s1)\n",
    "        features.loc[index,'number_of_nouns_s0'] = count_nouns(s0)\n",
    "        features.loc[index,'number_of_nouns_s1'] = count_nouns(s1)\n",
    "        features.loc[index,'number_of_verbs_s0'] = count_verbs(s0)\n",
    "        features.loc[index,'number_of_verbs_s1'] = count_verbs(s1)\n",
    "        features.loc[index,'number_of_symbols_s0'] = count_symbols(s0)\n",
    "        features.loc[index,'number_of_symbols_s1'] = count_symbols(s1)\n",
    "        features.loc[index,'number_of_digits_s0'] = count_digits(s0)\n",
    "        features.loc[index,'number_of_digits_1'] = count_digits(s1)\n",
    "    return features    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = feature_extractor(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_0_lengh</th>\n",
       "      <th>sentence_1_lengh</th>\n",
       "      <th>number_of_nouns_s0</th>\n",
       "      <th>number_of_nouns_s1</th>\n",
       "      <th>number_of_verbs_s0</th>\n",
       "      <th>number_of_verbs_s1</th>\n",
       "      <th>number_of_symbols_s0</th>\n",
       "      <th>number_of_symbols_s1</th>\n",
       "      <th>number_of_digits_s0</th>\n",
       "      <th>number_of_digits_1</th>\n",
       "      <th>quantity_of_synonims</th>\n",
       "      <th>quantity_of_shared_words</th>\n",
       "      <th>proper_nouns_shared</th>\n",
       "      <th>jaccard_distance</th>\n",
       "      <th>path_similarity</th>\n",
       "      <th>wup_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.58545</td>\n",
       "      <td>0.681905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.411797</td>\n",
       "      <td>0.535622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.212302</td>\n",
       "      <td>0.412094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_0_lengh sentence_1_lengh number_of_nouns_s0 number_of_nouns_s1  \\\n",
       "0               17               12                  2                  3   \n",
       "1                7               11                  2                  2   \n",
       "2                9               10                  3                  2   \n",
       "3               12               17                  4                  6   \n",
       "4               11               11                  3                  3   \n",
       "\n",
       "  number_of_verbs_s0 number_of_verbs_s1 number_of_symbols_s0  \\\n",
       "0                  1                  0                    1   \n",
       "1                  0                  0                    1   \n",
       "2                  1                  2                    1   \n",
       "3                  0                  0                    3   \n",
       "4                  0                  0                    5   \n",
       "\n",
       "  number_of_symbols_s1 number_of_digits_s0 number_of_digits_1  \\\n",
       "0                    1                   0                  0   \n",
       "1                    2                   0                  0   \n",
       "2                    4                   0                  0   \n",
       "3                    4                   0                  0   \n",
       "4                   11                   0                  0   \n",
       "\n",
       "  quantity_of_synonims quantity_of_shared_words proper_nouns_shared  \\\n",
       "0                    8                        9                   1   \n",
       "1                    4                        4                   0   \n",
       "2                    3                        3                   0   \n",
       "3                   12                       11                   2   \n",
       "4                    3                        3                   1   \n",
       "\n",
       "  jaccard_distance path_similarity wup_similarity  \n",
       "0             0.45         0.58545       0.681905  \n",
       "1         0.285714        0.628571          0.725  \n",
       "2           0.1875        0.411797       0.535622  \n",
       "3         0.611111               1              1  \n",
       "4         0.105263        0.212302       0.412094  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = feature_extractor(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3108, 16)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_noun(tag):\n",
    "    return tag in ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "\n",
    "def is_verb(tag):\n",
    "    return tag in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "\n",
    "def is_adverb(tag):\n",
    "    return tag in ['RB', 'RBR', 'RBS']\n",
    "\n",
    "def is_adjective(tag):\n",
    "    return tag in ['JJ', 'JJR', 'JJS']\n",
    "\n",
    "def penn_to_wn(tag):\n",
    "    if is_adjective(tag):\n",
    "        return wn.ADJ\n",
    "    elif is_noun(tag):\n",
    "        return wn.NOUN\n",
    "    elif is_adverb(tag):\n",
    "        return wn.ADV\n",
    "    elif is_verb(tag):\n",
    "        return wn.VERB\n",
    "    return wn.NOUN\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    tagger = PerceptronTagger()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    w_tokenizer = WhitespaceTokenizer()\n",
    "    s_tokenized = w_tokenizer.tokenize(text)\n",
    "    s_tagged = tagger.tag(s_tokenized)\n",
    "    return [lemmatizer.lemmatize(w[0],penn_to_wn(w[1])) for w in s_tagged]\n",
    "\n",
    "\n",
    "def preprocessing(data, return_array = False):\n",
    "    # todo: better handling of na\n",
    "    data = data.fillna('')\n",
    "    for column in data.columns:\n",
    "        print(column)\n",
    "        # remove the digits and puntuation\n",
    "#         data[column] = data[column].str.replace('\\d+', '')\n",
    "        # convert to lowercase\n",
    "        data[column] = data[column].str.replace('\\W+', ' ')\n",
    "        # replace continuous white spaces by a single one\n",
    "        data[column] = data[column].str.replace('\\s+', ' ')\n",
    "        # words to lower\n",
    "        data[column] = data[column].str.lower()\n",
    "        # spell corrector \n",
    "        # data[column] = data[column].apply(auto_spell)\n",
    "        # lematize\n",
    "        data[column] = data[column].apply(lemmatize_text)\n",
    "        if not return_array:\n",
    "            data[column] = data[column].str.join(' ')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence0\n",
      "sentence1\n",
      "sentence0\n",
      "sentence1\n"
     ]
    }
   ],
   "source": [
    "train_df = preprocessing(train_df)\n",
    "test_df = preprocessing(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence0</th>\n",
       "      <th>sentence1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>source close sale say vivendi keep door open b...</td>\n",
       "      <td>source close sale say vivendi keep door open b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>micron declare first quarterly profit three year</td>\n",
       "      <td>micron s number also mark first quarterly prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fine part fail republican effort force entice ...</td>\n",
       "      <td>perry say back senate s effort include fine fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>american anglican council represent episcopali...</td>\n",
       "      <td>american anglican council represent episcopali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tech load nasdaq composite rise point end high...</td>\n",
       "      <td>technology lace nasdaq composite index ixic cl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence0  \\\n",
       "0  source close sale say vivendi keep door open b...   \n",
       "1   micron declare first quarterly profit three year   \n",
       "2  fine part fail republican effort force entice ...   \n",
       "3  american anglican council represent episcopali...   \n",
       "4  tech load nasdaq composite rise point end high...   \n",
       "\n",
       "                                           sentence1  \n",
       "0  source close sale say vivendi keep door open b...  \n",
       "1  micron s number also mark first quarterly prof...  \n",
       "2  perry say back senate s effort include fine fo...  \n",
       "3  american anglican council represent episcopali...  \n",
       "4  technology lace nasdaq composite index ixic cl...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence0</th>\n",
       "      <th>sentence1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>problem likely mean corrective change shuttle ...</td>\n",
       "      <td>say problem need correct space shuttle fleet c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>technology lace nasdaq composite index ixic in...</td>\n",
       "      <td>broad standard poor s index spx inched point p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it s huge black eye say publisher arthur ochs ...</td>\n",
       "      <td>it s huge black eye arthur sulzberger newspape...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sec chairman william donaldson say building co...</td>\n",
       "      <td>i think there s building confidence cop beat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vivendi share close percent euro paris fall pe...</td>\n",
       "      <td>new york vivendi share percent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence0  \\\n",
       "0  problem likely mean corrective change shuttle ...   \n",
       "1  technology lace nasdaq composite index ixic in...   \n",
       "2  it s huge black eye say publisher arthur ochs ...   \n",
       "3  sec chairman william donaldson say building co...   \n",
       "4  vivendi share close percent euro paris fall pe...   \n",
       "\n",
       "                                           sentence1  \n",
       "0  say problem need correct space shuttle fleet c...  \n",
       "1  broad standard poor s index spx inched point p...  \n",
       "2  it s huge black eye arthur sulzberger newspape...  \n",
       "3       i think there s building confidence cop beat  \n",
       "4                     new york vivendi share percent  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train pearson:  0.7217647820584595\n",
      "test pearson:  0.574696530819923\n"
     ]
    }
   ],
   "source": [
    "def lexical_simmilarity(df):\n",
    "    guess = pd.DataFrame()\n",
    "    for i in df.index:\n",
    "        guess.loc[i,'labels'] = 1 - jaccard_distance(set(df.loc[i,'sentence0']), set(df.loc[i,'sentence1']))\n",
    "    return guess\n",
    "\n",
    "\n",
    "\n",
    "guess_lex_train = lexical_simmilarity(train_df)\n",
    "guess_lex_test = lexical_simmilarity(test_df)\n",
    "\n",
    "print('train pearson: ', pearsonr(guess_lex_train['labels'], train_gs['labels'])[0])\n",
    "print('test pearson: ', pearsonr(guess_lex_test['labels'], test_gs['labels'])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train pearson:  0.5295427393418783\n",
      "test pearson: 0.5946085106941639\n"
     ]
    }
   ],
   "source": [
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(item) for item in tokens]\n",
    "\n",
    "\n",
    "def normalize(text):\n",
    "    return stem_tokens(nltk.word_tokenize(text.lower().translate(remove_punctuation_map)))\n",
    "\n",
    "\n",
    "tfv = TfidfVectorizer(max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
    "tfv.fit(list(train_df['sentence1']) + list(train_df['sentence0']) )\n",
    "\n",
    "def return_simil(a,b):\n",
    "    simil = tfv.transform([a,b])\n",
    "    return ((simil * simil.T).A)[0,1]\n",
    "\n",
    "def calculate_all_sims(df):\n",
    "    results = []\n",
    "    for i in df.values:\n",
    "        results.append(return_simil(i[0], i[1]))\n",
    "    return results\n",
    "\n",
    "\n",
    "all_sims = calculate_all_sims(train_df)\n",
    "test_sims = calculate_all_sims(test_df)\n",
    "\n",
    "print('train pearson: ', pearsonr(all_sims, train_gs['labels'])[0])\n",
    "print('test pearson:', pearsonr(test_sims, test_gs['labels'])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merged train with TfidVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sentences = train_df['sentence0'] + train_df['sentence1']\n",
    "merged_test = test_df['sentence0'] + test_df['sentence1']\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "merged_train = vectorizer.fit_transform(merged_sentences)\n",
    "merged_test = vectorizer.transform(merged_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence0\n",
      "sentence1\n",
      "No of words in the dictionary = 1771\n",
      "sentence0\n",
      "sentence1\n",
      "(2234, 1771)\n",
      "(3108, 1771)\n"
     ]
    }
   ],
   "source": [
    "def train_dictionary(df):\n",
    "    \n",
    "    sentences_tokenized = df.sentence0.tolist() + df.sentence1.tolist()\n",
    "    \n",
    "    dictionary = corpora.Dictionary(sentences_tokenized)\n",
    "    dictionary.filter_extremes(no_below=5, no_above=0.8)\n",
    "    dictionary.compactify()\n",
    "    \n",
    "    return dictionary\n",
    "    \n",
    "def get_vectors(df, dictionary):\n",
    "    \n",
    "    sentence0_vec = [dictionary.doc2bow(text) for text in df.sentence0.tolist()]\n",
    "    sentence1_vec = [dictionary.doc2bow(text) for text in df.sentence1.tolist()]\n",
    "    \n",
    "    sentence0_csc = gensim.matutils.corpus2csc(sentence0_vec, num_terms=len(dictionary.token2id))\n",
    "    sentence1_csc = gensim.matutils.corpus2csc(sentence1_vec, num_terms=len(dictionary.token2id))\n",
    "    \n",
    "    return sentence0_csc.transpose(),sentence1_csc.transpose()\n",
    "\n",
    "tokenized_train = preprocessing(train_df, return_array = True)\n",
    "dictionary = train_dictionary(tokenized_train)\n",
    "print (\"No of words in the dictionary = %s\" %len(dictionary))\n",
    "\n",
    "tokenized_test = preprocessing(test_df, return_array = True)\n",
    "\n",
    "q1_csc, q2_csc = get_vectors(tokenized_train, dictionary)\n",
    "q1_csc_test, q2_csc_test = get_vectors(tokenized_test, dictionary)\n",
    "\n",
    "print (q1_csc.shape)\n",
    "print (q1_csc_test.shape)\n",
    "\n",
    "train_bog = np.concatenate((q1_csc.todense(), q2_csc.todense()), axis=1)\n",
    "test_bog = np.concatenate((q1_csc_test.todense(), q2_csc_test.todense()), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bog_extended = pd.concat([pd.DataFrame(train_bog),train_features],axis=1)\n",
    "test_bog_extended = pd.concat([pd.DataFrame(test_bog),test_features],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model,xtrain,xtest):\n",
    "    train_predicted =  model.predict(xtrain)\n",
    "    test_predicted =   model.predict(xtest)\n",
    "    print('train pearson: ', pearsonr(train_predicted, train_gs['labels'])[0])\n",
    "    print('test pearson: ', pearsonr(test_predicted, test_gs['labels'])[0])\n",
    "\n",
    "def train_and_test_model(model, train,test,model_name='model'):\n",
    "    model.fit(train,train_gs)\n",
    "    test_model(model,train,test)\n",
    "    if model_name == 'rfr':\n",
    "        print_feature_importance(rfr,train)\n",
    "\n",
    "    \n",
    "\n",
    "def print_feature_importance(rfr,train):\n",
    "    importances=rfr.feature_importances_ ## get the feature importance\n",
    "    # print(\"Original \",np.argsort(importances))\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    try:\n",
    "        feat_labels = train.columns\n",
    "    except:\n",
    "        return\n",
    "    for f in range(10):\n",
    "        print(\"%2d) %-*s %f\" % (f+1,30,feat_labels[indices[f]],\n",
    "                                        importances[indices[f]]))\n",
    "        \n",
    "def run_with_all_datasets(model,model_name):\n",
    "    print(model_name)\n",
    "    print('Only Features')\n",
    "    train_and_test_model(model,train_features,test_features,model_name)\n",
    "#     print('Only TifVectorizer')\n",
    "#     train_and_test_model(model,merged_train,merged_test,model_name)\n",
    "    print('Only Bag of Words')\n",
    "#     train_and_test_model(model,train_bog,test_bog,model_name)\n",
    "    print('Bag of Words + features')\n",
    "    train_and_test_model(model,train_bog_extended,test_bog_extended,model_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_nn = MLPRegressor(hidden_layer_sizes=(2,),validation_fraction=0.3, alpha=0.3,warm_start=False,max_iter=1000)\n",
    "# run_with_all_datasets(model_nn,'Neural networks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn cv\n",
      "Only Features\n",
      "train pearson:  0.7526610765116355\n",
      "test pearson:  0.5045663415576055\n",
      "Only Bag of Words\n",
      "Bag of Words + features\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-13857d84812b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m               'hidden_layer_sizes':np.arange(1, 8),'solver': ['lbfgs','adam'],'warm_start': [False]}\n\u001b[0;32m      3\u001b[0m \u001b[0mnn_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLPRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mrun_with_all_datasets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn_cv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'nn cv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-40-990706b78361>\u001b[0m in \u001b[0;36mrun_with_all_datasets\u001b[1;34m(model, model_name)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m#     train_and_test_model(model,train_bog,test_bog,model_name)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Bag of Words + features'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mtrain_and_test_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_bog_extended\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_bog_extended\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-990706b78361>\u001b[0m in \u001b[0;36mtrain_and_test_model\u001b[1;34m(model, train, test, model_name)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_and_test_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_gs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'rfr'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    697\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parameters = {'alpha': 10.0 ** -np.arange(0, 5), 'max_iter':[1000],\n",
    "              'hidden_layer_sizes':np.arange(1, 8),'solver': ['lbfgs','adam'],'warm_start': [False]}\n",
    "nn_cv = GridSearchCV(MLPRegressor(), parameters, n_jobs=-1)\n",
    "run_with_all_datasets(nn_cv,'nn cv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfr\n",
      "Only Features\n",
      "train pearson:  0.9695574315963053\n",
      "test pearson:  0.614033817336285\n",
      " 1) quantity_of_synonims           0.264220\n",
      " 2) quantity_of_shared_words       0.262934\n",
      " 3) jaccard_distance               0.076380\n",
      " 4) path_similarity                0.074520\n",
      " 5) wup_similarity                 0.072787\n",
      " 6) sentence_0_lengh               0.051450\n",
      " 7) sentence_1_lengh               0.039849\n",
      " 8) number_of_symbols_s0           0.037343\n",
      " 9) number_of_nouns_s1             0.030614\n",
      "10) number_of_nouns_s0             0.028691\n",
      "Only Bag of Words\n",
      "Bag of Words + features\n",
      "train pearson:  0.9787421187106379\n",
      "test pearson:  0.6344399490626556\n",
      " 1) quantity_of_shared_words       0.254998\n",
      " 2) quantity_of_synonims           0.241956\n",
      " 3) jaccard_distance               0.051009\n",
      " 4) path_similarity                0.028215\n",
      " 5) sentence_0_lengh               0.027976\n",
      " 6) wup_similarity                 0.023840\n",
      " 7) 43                             0.020170\n",
      " 8) sentence_1_lengh               0.017198\n",
      " 9) 87                             0.015331\n",
      "10) number_of_symbols_s0           0.011466\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_jobs=-1,n_estimators=100)\n",
    "run_with_all_datasets(rfr,'rfr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "svr = SVR()\n",
    "run_with_all_datasets(svr,'svr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try using all the distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "minkowski_dis = DistanceMetric.get_metric('minkowski')\n",
    "mms_scale_man = MinMaxScaler()\n",
    "mms_scale_euc = MinMaxScaler()\n",
    "mms_scale_mink = MinMaxScaler()\n",
    "\n",
    "def get_similarity_values(q1_csc, q2_csc):\n",
    "    cosine_sim = []\n",
    "    manhattan_dis = []\n",
    "    eucledian_dis = []\n",
    "    jaccard_dis = []\n",
    "    minkowsk_dis = []\n",
    "    \n",
    "    for i,j in zip(q1_csc, q2_csc):\n",
    "        sim = cs(i,j)\n",
    "        cosine_sim.append(sim[0][0])\n",
    "        sim = md(i,j)\n",
    "        manhattan_dis.append(sim[0][0])\n",
    "        sim = ed(i,j)\n",
    "        eucledian_dis.append(sim[0][0])\n",
    "        i_ = i.toarray()\n",
    "        j_ = j.toarray()\n",
    "        try:\n",
    "            sim = jsc(i_,j_)\n",
    "            jaccard_dis.append(sim)\n",
    "        except:\n",
    "            jaccard_dis.append(0)\n",
    "            \n",
    "        sim = minkowski_dis.pairwise(i_,j_)\n",
    "        minkowsk_dis.append(sim[0][0])\n",
    "    \n",
    "    return cosine_sim, manhattan_dis, eucledian_dis, jaccard_dis, minkowsk_dis    \n",
    "\n",
    "\n",
    "# cosine_sim = get_cosine_similarity(q1_csc, q2_csc)\n",
    "cosine_sim, manhattan_dis, eucledian_dis, jaccard_dis, minkowsk_dis = get_similarity_values(q1_csc, q2_csc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test pearson:  0.4378702270667962\n",
      "test pearson:  -0.31531007690103097\n",
      "test pearson:  -0.34482191037522353\n",
      "test pearson:  0.4235139147060639\n",
      "test pearson:  -0.34482191037522353\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def calculate_logloss(y_true, y_pred):\n",
    "    loss_cal = log_loss(y_true, y_pred)\n",
    "    return loss_cal\n",
    "\n",
    "y_pred_cos, y_pred_man, y_pred_euc, y_pred_jac, y_pred_mink = get_similarity_values(q1_csc_test, q2_csc_test)\n",
    "predictions = [y_pred_cos, y_pred_man, y_pred_euc, y_pred_jac, y_pred_mink]\n",
    "for test_predicted in predictions:\n",
    "    print('test pearson: ', pearsonr(test_predicted, test_gs['labels'])[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test pearson:  0.46914188670845747\n",
      "test pearson:  0.48925671621524475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "X_train = pd.DataFrame({\"cos\" : cosine_sim, \"man\" : manhattan_dis, \"euc\" : eucledian_dis, \"jac\" : jaccard_dis, \"min\" : minkowsk_dis})\n",
    "\n",
    "X_test = pd.DataFrame({\"cos\" : y_pred_cos, \"man\" : y_pred_man, \"euc\" : y_pred_euc, \"jac\" : y_pred_jac, \"min\" : y_pred_mink})\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train,train_gs.values.ravel())\n",
    "\n",
    "svr = SVR()\n",
    "svr.fit(X_train,train_gs.values.ravel())\n",
    "\n",
    "y_rfr_predicted = rfr.predict(X_test)\n",
    "y_svr_predicted = svr.predict(X_test)\n",
    "\n",
    "print('test pearson: ', pearsonr(y_rfr_predicted, test_gs['labels'])[0])\n",
    "print('test pearson: ', pearsonr(y_svr_predicted, test_gs['labels'])[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
