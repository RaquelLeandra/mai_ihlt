{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mandatory 2 - Session 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statement:\n",
    "* Read all pairs of sentences of the trial set within the\n",
    "evaluation framework of the project.\n",
    "* Compute the Jaccard similarity of each pair using the\n",
    "dependency triples from CoreNLPDependencyParser.\n",
    "* Show the results. Do you think it could be relevant to use\n",
    "NEs to compute the similarity between two sentences?\n",
    "Justify the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First read the data sets using pandas ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from nltk.parse.corenlp import CoreNLPDependencyParser\n",
    "from scipy.stats   import pearsonr\n",
    "from copy          import deepcopy\n",
    "from nltk.metrics  import jaccard_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence0</th>\n",
       "      <th>sentence1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id1</th>\n",
       "      <td>The bird is bathing in the sink.</td>\n",
       "      <td>Birdie is washing itself in the water basin.\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id2</th>\n",
       "      <td>In May 2010, the troops attempted to invade Ka...</td>\n",
       "      <td>The US army invaded Kabul on May 7th last year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id3</th>\n",
       "      <td>John said he is considered a witness but not a...</td>\n",
       "      <td>\"He is not a suspect anymore.\" John said.\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id4</th>\n",
       "      <td>They flew out of the nest in groups.</td>\n",
       "      <td>They flew into the nest together.\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id5</th>\n",
       "      <td>The woman is playing the violin.</td>\n",
       "      <td>The young lady enjoys listening to the guitar.\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id6</th>\n",
       "      <td>John went horse back riding at dawn with a who...</td>\n",
       "      <td>Sunrise at dawn is a magnificent view to take ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence0  \\\n",
       "id1                   The bird is bathing in the sink.   \n",
       "id2  In May 2010, the troops attempted to invade Ka...   \n",
       "id3  John said he is considered a witness but not a...   \n",
       "id4               They flew out of the nest in groups.   \n",
       "id5                   The woman is playing the violin.   \n",
       "id6  John went horse back riding at dawn with a who...   \n",
       "\n",
       "                                             sentence1  \n",
       "id1     Birdie is washing itself in the water basin.\\r  \n",
       "id2  The US army invaded Kabul on May 7th last year...  \n",
       "id3        \"He is not a suspect anymore.\" John said.\\r  \n",
       "id4                They flew into the nest together.\\r  \n",
       "id5   The young lady enjoys listening to the guitar.\\r  \n",
       "id6  Sunrise at dawn is a magnificent view to take ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_path    = 'data/trial/STS.input.txt'\n",
    "trial_gs_path = 'data/trial/STS.gs.txt'\n",
    "trial_df      = pd.read_csv(trial_path, sep='\\t', lineterminator='\\n', names=['sentence0','sentence1'], header=None, quoting=csv.QUOTE_NONE)\n",
    "trial_gs      = pd.read_csv(trial_gs_path, sep='\\t', lineterminator='\\n', names=['labels'], header=None, quoting=csv.QUOTE_NONE).iloc[::-1]\n",
    "trial_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the CoreNLPDependencyParser\n",
    "\n",
    "_java -Xmx5g -cp C:\\stanford-corenlp-full-2018-10-05\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = CoreNLPDependencyParser(url='http://localhost:9000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two next functions are used to calculate the similarities using the Jaccard distances (the same as in Session 2) with a list of words and the pearson correlation coefficient as well... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_simmilarity(df):\n",
    "    \"\"\" Calculate the similarities using the Jaccard distance \"\"\"\n",
    "    guess = pd.DataFrame()\n",
    "    for i in df.index:\n",
    "        set1 = set(df.loc[i,'sentence0'])\n",
    "        set2 = set(df.loc[i,'sentence1'])\n",
    "        guess.loc[i,'labels'] = 1. - jaccard_distance(set1, set2)\n",
    "    return guess\n",
    "\n",
    "def analyze_results(results):\n",
    "    \"\"\" Print similarities and pearson correlation coefficient \"\"\"\n",
    "    guess_lex = lexical_simmilarity(results)\n",
    "    pearson    = pearsonr(trial_gs['labels'], guess_lex['labels'])[0]\n",
    "    print(results)\n",
    "    print()\n",
    "    print('Similarities:\\n', guess_lex)\n",
    "    print()\n",
    "    print('Pearson correlation index:', pearson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing function just starts applies the DependencyParser to each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    data = data.fillna('')\n",
    "    for column in data.columns:\n",
    "        # get triplets\n",
    "        data[column] = data[column].apply(apply_dependency_triplets)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results after applying the Jaccard distance to the __whole__ dependency triples...\n",
    "\n",
    "_Conclusions at the end_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             sentence0  \\\n",
      "id1  [((sink, NN), det, (the, DT)), ((sink, NN), ca...   \n",
      "id2  [((invade, VB), dobj, (kabul, NN)), ((invade, ...   \n",
      "id3  [((considered, VBN), nsubjpass, (he, PRP)), ((...   \n",
      "id4  [((flew, VBD), nmod, (groups, NNS)), ((groups,...   \n",
      "id5  [((playing, VBG), nsubj, (woman, NN)), ((woman...   \n",
      "id6  [((friends, NNS), case, (of, IN)), ((group, NN...   \n",
      "\n",
      "                                             sentence1  \n",
      "id1  [((washing, VBG), nsubj, (birdie, NN)), ((wash...  \n",
      "id2  [((year, NN), amod, (last, JJ)), ((invaded, VB...  \n",
      "id3  [((suspect, JJ), nsubj, (he, PRP)), ((suspect,...  \n",
      "id4  [((flew, VBD), nmod, (nest, NN)), ((nest, NN),...  \n",
      "id5  [((lady, NN), det, (the, DT)), ((enjoys, VBZ),...  \n",
      "id6  [((view, NN), amod, (magnificent, JJ)), ((take...  \n",
      "\n",
      "Similarities:\n",
      "        labels\n",
      "id1  0.000000\n",
      "id2  0.000000\n",
      "id3  0.000000\n",
      "id4  0.400000\n",
      "id5  0.000000\n",
      "id6  0.033333\n",
      "\n",
      "Pearson correlation index: -0.1879821089440828\n"
     ]
    }
   ],
   "source": [
    "def apply_dependency_triplets(sentence):\n",
    "    result = set()\n",
    "    parse = parser.raw_parse(sentence.lower())\n",
    "    tree = next(parse)\n",
    "    for t in tree.triples():\n",
    "        result.add(t)\n",
    "    return list(result)\n",
    "\n",
    "analyze_results(\n",
    "    preprocessing(deepcopy(trial_df))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results after applying the Jaccard distance to the dependency triples. This time the triplets are split into three elements ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             sentence0  \\\n",
      "id1  [nmod, (the, DT), case, det, (in, IN), (bird, ...   \n",
      "id2  [nmod, case, (attempted, VBN), (in, IN), aux, ...   \n",
      "id3  [(he, PRP), auxpass, conj, det, (a, DT), ccomp...   \n",
      "id4  [nmod, case, (the, DT), det, (groups, NNS), (i...   \n",
      "id5  [(the, DT), aux, det, (violin, NN), (playing, ...   \n",
      "id6  [nmod, (a, DT), (at, IN), punct, amod, advmod,...   \n",
      "\n",
      "                                             sentence1  \n",
      "id1  [(washing, VBG), nmod, aux, dobj, (itself, PRP...  \n",
      "id2  [nmod, (the, DT), aux, (invaded, VBD), nmod:tm...  \n",
      "id3  [(he, PRP), det, (a, DT), ('', ''), (``, ``), ...  \n",
      "id4  [nmod, case, (the, DT), det, (nest, NN), (., ....  \n",
      "id5  [nmod, (the, DT), (listening, VBG), det, case,...  \n",
      "id6  [nmod, (a, DT), (at, IN), advcl, cop, (to, TO)...  \n",
      "\n",
      "Similarities:\n",
      "        labels\n",
      "id1  0.428571\n",
      "id2  0.433333\n",
      "id3  0.285714\n",
      "id4  0.588235\n",
      "id5  0.238095\n",
      "id6  0.285714\n",
      "\n",
      "Pearson correlation index: 0.40556896256359354\n"
     ]
    }
   ],
   "source": [
    "def apply_dependency_triplets(sentence):\n",
    "    result = set()\n",
    "    parse = parser.raw_parse(sentence.lower())\n",
    "    tree = next(parse)\n",
    "    for t in tree.triples():\n",
    "        result.add(t[0])\n",
    "        result.add(t[1])\n",
    "        result.add(t[2])\n",
    "    return list(result)\n",
    "\n",
    "analyze_results(\n",
    "    preprocessing(deepcopy(trial_df))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, each element in the triplet is added separatedly ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             sentence0  \\\n",
      "id1  [nmod, case, in, det, ., sink, NN, cop, is, pu...   \n",
      "id2  [nmod, aux, ,, VB, punct, the, 2010, attempted...   \n",
      "id3  [conj, ccomp, not, RB, suspect, punct, but, cc...   \n",
      "id4  [nmod, case, in, det, groups, ., they, NN, fle...   \n",
      "id5  [VBG, violin, aux, det, playing, NN, is, punct...   \n",
      "id6  [nmod, riding, with, punct, amod, VBD, advmod,...   \n",
      "\n",
      "                                             sentence1  \n",
      "id1  [VBG, nmod, aux, case, itself, in, det, birdie...  \n",
      "id2  [nmod, aux, ,, VB, nmod:tmod, punct, the, 2010...  \n",
      "id3  [anymore, JJ, det, not, ``, neg, root, suspect...  \n",
      "id4  [nmod, case, into, det, they, NN, flew, togeth...  \n",
      "id5  [VBG, nmod, guitar, det, case, listening, xcom...  \n",
      "id6  [nmod, VBP, VB, advcl, cop, punct, amod, sunri...  \n",
      "\n",
      "Similarities:\n",
      "        labels\n",
      "id1  0.434783\n",
      "id2  0.388889\n",
      "id3  0.281250\n",
      "id4  0.600000\n",
      "id5  0.291667\n",
      "id6  0.260000\n",
      "\n",
      "Pearson correlation index: 0.3506001934267482\n"
     ]
    }
   ],
   "source": [
    "def apply_dependency_triplets(sentence):\n",
    "    result = set()\n",
    "    parse = parser.raw_parse(sentence.lower())\n",
    "    tree = next(parse)\n",
    "    for t in tree.triples():\n",
    "        result.add(t[0][0])\n",
    "        result.add(t[0][1])\n",
    "        result.add(t[1])\n",
    "        result.add(t[2][0])\n",
    "        result.add(t[2][0])\n",
    "    return list(result)\n",
    "\n",
    "analyze_results(\n",
    "    preprocessing(deepcopy(trial_df))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "Final results, pearson correlation index: \n",
    "* Whole triplets: -0.1879821089440828\n",
    "* Triplets splitted in 3: 0.40556896256359354\n",
    "* All elements in triplets splitted: 0.3506001934267482\n",
    "\n",
    "It can be seen that using whole triplets does not work to compare the sentences. We are just making a sintactic analysis tree that may or may not contain enough information to find the real correlation between two sentences. It can be seen though that in the other two cases, the index is still really small, but it's better than the first. This happens because some words are repeated between correlated sentences, so they are probably given the same category in the analysed tree, thus making the final Jaccard distance smaller. \n",
    "\n",
    "In conclusion, this tool is not enough, it will just serve as extra information for the other ones like semantic analysis that were previusly used in the subject."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
