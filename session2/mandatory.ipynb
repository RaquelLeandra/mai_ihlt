{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mandatory exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import urllib.request\n",
    "from nltk.metrics import jaccard_distance\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read all pairs of sentences of the trial set within the\n",
    "evaluation framework of the project.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id1 ['The bird is bathing in the sink.', 'Birdie is washing itself in the water basin.']\n",
      "id2 ['In May 2010, the troops attempted to invade Kabul.', 'The US army invaded Kabul on May 7th last year, 2010.']\n",
      "id3 ['John said he is considered a witness but not a suspect.', '\"He is not a suspect anymore.\" John said.']\n",
      "id4 ['They flew out of the nest in groups.', 'They flew into the nest together.']\n",
      "id5 ['The woman is playing the violin.', 'The young lady enjoys listening to the guitar.']\n",
      "id6 ['John went horse back riding at dawn with a whole group of friends.', 'Sunrise at dawn is a magnificent view to take in if you wake up early enough for it.']\n"
     ]
    }
   ],
   "source": [
    "pairs = {}\n",
    "\n",
    "with open('trial/STS.input.txt', 'r') as f:\n",
    "    for l in f:\n",
    "        sid = l.split('\\t')[0]\n",
    "        s1  = l.split('\\t')[1]\n",
    "        s2  = l.split('\\t')[2][:-1] # Remove the \\n character\n",
    "        pairs[sid] = [s1, s2]\n",
    "        print(sid, pairs[sid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute their similarities by considering words and Jaccard distance.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: id1 similarity [0-1]: 0.33333333333333337\n",
      "id: id2 similarity [0-1]: 0.33333333333333337\n",
      "id: id3 similarity [0-1]: 0.5714285714285714\n",
      "id: id4 similarity [0-1]: 0.4545454545454546\n",
      "id: id5 similarity [0-1]: 0.16666666666666663\n",
      "id: id6 similarity [0-1]: 0.13793103448275867\n"
     ]
    }
   ],
   "source": [
    "simmilarities = []\n",
    "for sid in pairs:\n",
    "    s1      = pairs[sid][0]\n",
    "    s2      = pairs[sid][1]\n",
    "    words_1 = set([word.lower() for word in nltk.word_tokenize(s1)])\n",
    "    words_2 = set([word.lower() for word in nltk.word_tokenize(s2)])\n",
    "    jaccard_simmilarity = 1 - jaccard_distance(words_1, words_2)\n",
    "    simmilarities.append(jaccard_simmilarity) \n",
    "    print('id:', sid, 'similarity [0-1]:', jaccard_simmilarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare the previous results with gold standard by giving the pearson correlation between them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5140573923420935\n"
     ]
    }
   ],
   "source": [
    "gs = {}\n",
    "\n",
    "with open('trial/STS.gs.txt', 'r') as f:\n",
    "    for l in f:\n",
    "        sid     = l.split('\\t')[0]\n",
    "        value   = abs( int(l.split('\\t')[1])-5)    \n",
    "        gs[sid] = value\n",
    "\n",
    "refs = list(gs.values())\n",
    "print(pearsonr(refs, simmilarities)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain a correlation coefficient of 0.5140573923420935. \n",
    "\n",
    "As we are comparing two arrays of similarity values, we obtain a positive correlation. \n",
    "\n",
    "This value is a little bigger than 0.5, this means that there is little correlation between the two arrays, so probably the Jaccard distance isn't the best way to measure the semantic similarity between sentences. \n",
    "\n",
    "These results are due to the definition of Jaccard distance. This definition is fully based on set theory and does not take into account the semantic relationship between words (like synonymity)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
