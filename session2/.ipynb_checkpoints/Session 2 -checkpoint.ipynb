{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.metrics import jaccard_distance\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Read all pairs of sentences on the trial set .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id1 ['The bird is bathing in the sink.', 'Birdie is washing itself in the water basin.']\n",
      "id2 ['In May 2010, the troops attempted to invade Kabul.', 'The US army invaded Kabul on May 7th last year, 2010.']\n",
      "id3 ['John said he is considered a witness but not a suspect.', '\"He is not a suspect anymore.\" John said.']\n",
      "id4 ['They flew out of the nest in groups.', 'They flew into the nest together.']\n",
      "id5 ['The woman is playing the violin.', 'The young lady enjoys listening to the guitar.']\n",
      "id6 ['John went horse back riding at dawn with a whole group of friends.', 'Sunrise at dawn is a magnificent view to take in if you wake up early enough for it.']\n"
     ]
    }
   ],
   "source": [
    "f = open('trial/STS.input.txt','r')\n",
    "pairs = {}\n",
    "for l in f:\n",
    "    sid = l.split('\\t')[0]\n",
    "    s1 = l.split('\\t')[1]\n",
    "    s2 = l.split('\\t')[2][:-1]\n",
    "    pairs[sid] = [s1,s2]\n",
    "    print(sid,pairs[sid])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id1 distance: 0.6923076923076923\n",
      "id2 distance: 0.7368421052631579\n",
      "id3 distance: 0.5333333333333333\n",
      "id4 distance: 0.5454545454545454\n",
      "id5 distance: 0.7692307692307693\n",
      "id6 distance: 0.8620689655172413\n"
     ]
    }
   ],
   "source": [
    "distances = []\n",
    "for sid in pairs:\n",
    "    s1 = pairs[sid][0]\n",
    "    s2 = pairs[sid][1]\n",
    "    words_1 = nltk.word_tokenize(s1)\n",
    "    words_2 = nltk.word_tokenize(s2)\n",
    "    #print(words_1,words_2)\n",
    "    distances.append(jaccard_distance(set(words_1),set(words_2))) \n",
    "    print(sid,'distance:', jaccard_distance(set(words_1),set(words_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the previous results with gold standard by giving the pearson correlation between them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3962389776119233\n"
     ]
    }
   ],
   "source": [
    "f = open('trial/STS.gs.txt','r')\n",
    "\n",
    "gs = {}\n",
    "for l in f:\n",
    "    sid = l.split('\\t')[0]\n",
    "    value = abs( int(l.split('\\t')[1])-5)    \n",
    "    gs[sid] = value\n",
    "f.close()\n",
    "\n",
    "refs = list(gs.values())\n",
    "print(pearsonr(refs,distances)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain an inverse correlation coeficient. The reason for this behaviour is that the gold standart values are bigger when the sentences are more similar, but the jaccard distance is lower in that case. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
