{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mandatory Session 7\n",
    "Using ***nltk.ne_chunk*** and ***CoreNLPParser***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from scipy.stats   import pearsonr\n",
    "from copy          import deepcopy\n",
    "from nltk.metrics  import jaccard_distance\n",
    "from nltk          import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree     import Tree\n",
    "from nltk.parse    import CoreNLPParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First read the data sets using pandas ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence0</th>\n",
       "      <th>sentence1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id1</th>\n",
       "      <td>The bird is bathing in the sink.</td>\n",
       "      <td>Birdie is washing itself in the water basin.\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id2</th>\n",
       "      <td>In May 2010, the troops attempted to invade Ka...</td>\n",
       "      <td>The US army invaded Kabul on May 7th last year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id3</th>\n",
       "      <td>John said he is considered a witness but not a...</td>\n",
       "      <td>\"He is not a suspect anymore.\" John said.\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id4</th>\n",
       "      <td>They flew out of the nest in groups.</td>\n",
       "      <td>They flew into the nest together.\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id5</th>\n",
       "      <td>The woman is playing the violin.</td>\n",
       "      <td>The young lady enjoys listening to the guitar.\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id6</th>\n",
       "      <td>John went horse back riding at dawn with a who...</td>\n",
       "      <td>Sunrise at dawn is a magnificent view to take ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence0  \\\n",
       "id1                   The bird is bathing in the sink.   \n",
       "id2  In May 2010, the troops attempted to invade Ka...   \n",
       "id3  John said he is considered a witness but not a...   \n",
       "id4               They flew out of the nest in groups.   \n",
       "id5                   The woman is playing the violin.   \n",
       "id6  John went horse back riding at dawn with a who...   \n",
       "\n",
       "                                             sentence1  \n",
       "id1     Birdie is washing itself in the water basin.\\r  \n",
       "id2  The US army invaded Kabul on May 7th last year...  \n",
       "id3        \"He is not a suspect anymore.\" John said.\\r  \n",
       "id4                They flew into the nest together.\\r  \n",
       "id5   The young lady enjoys listening to the guitar.\\r  \n",
       "id6  Sunrise at dawn is a magnificent view to take ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_path    = 'data/trial/STS.input.txt'\n",
    "trial_gs_path = 'data/trial/STS.gs.txt'\n",
    "trial_df      = pd.read_csv(trial_path, sep='\\t', lineterminator='\\n', names=['sentence0','sentence1'], header=None, quoting=csv.QUOTE_NONE)\n",
    "trial_gs      = pd.read_csv(trial_gs_path, sep='\\t', lineterminator='\\n', names=['labels'], header=None, quoting=csv.QUOTE_NONE).iloc[::-1]\n",
    "trial_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing function will apply one of the name entity parser functions to the data only. Some *real* preprocessing should be done here. For example, removing stopwords..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data, ne_parser_function): # Name entity parser function is passed as an argument\n",
    "    \"\"\" This preprocessing only uses the name entity parser functions. Generaly a more complete function will be used \"\"\"\n",
    "    data = data.fillna('')\n",
    "    for column in data.columns:\n",
    "        data[column] = data[column].apply(ne_parser_function)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two next functions are used to calculate the similarities using the Jaccard distances (the same as in Session 2) with a list of words and the pearson correlation coefficient as well... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_simmilarity(df):\n",
    "    \"\"\" Calculate the similarities using the Jaccard distance \"\"\"\n",
    "    guess = pd.DataFrame()\n",
    "    for i in df.index:\n",
    "        set1 = set(df.loc[i,'sentence0'])\n",
    "        set2 = set(df.loc[i,'sentence1'])\n",
    "        guess.loc[i,'labels'] = 1. - jaccard_distance(set1, set2)\n",
    "    return guess\n",
    "\n",
    "def analyzeResults(results):\n",
    "    \"\"\" Print similarities and pearson correlation coefficient \"\"\"\n",
    "    guess_lex = lexical_simmilarity(results)\n",
    "    pearson    = pearsonr(trial_gs['labels'], guess_lex['labels'])[0]\n",
    "    for column in results.columns:\n",
    "        print('\\n', column)\n",
    "        results[column].apply(print)\n",
    "    print()\n",
    "    print('Similarities:\\n', guess_lex)\n",
    "    print()\n",
    "    print('Pearson correlation index:', pearson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the two *Name Entity Parser* functions are defined. First the nltk parser which is supossed to receive as an argument the tree obtained by an *nltk.ne_chunk* parser. The binary tree is transformed into a flat list, where words in the same branch corresponding to a name entity are now thogether in the same string..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_parser(tree):\n",
    "    \"\"\" Parse a tree obtained using the nltk ne_chunk parser \"\"\"\n",
    "    parsed_array = []\n",
    "    for chunk in tree: \n",
    "        if type(chunk) == Tree:\n",
    "            word = ' '.join(leaf[0] for leaf in chunk)\n",
    "            parsed_array.append(word.lower())\n",
    "        else: \n",
    "            parsed_array.append(chunk[0].lower())\n",
    "    \n",
    "    return [i for i in parsed_array if i.isalnum()] # Remove non-alphanumeric cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, the parser from *CoreNLP* is first created using the constructor (the *tagtype* argument indicates a name entity parser). The constructor needs a *CoreNLP* server to be up, in this case this server is supposed to be running in the local machine. The server can be launched using the next command:\n",
    "\n",
    "````java -mx4g -cp path_to\\stanford-corenlp-full-2018-10-05\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000````\n",
    "\n",
    "The parser functions expects a list created by the *CoreNLPParser.tag* method and for each group of words with tags other than ````'O'```` it will generate a single string grouping them, e.g. ````[('John', 'PERSON'), ('Smith', 'PERSON)] => ['John Smith']````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = CoreNLPParser(url='http://localhost:9000', tagtype='ner')\n",
    "\n",
    "def nlp_parser(tagged):\n",
    "    \"\"\" Parse a list obtained using the CoreNLPParser.tag parser \"\"\"\n",
    "    parsed      = []\n",
    "    last_tag    = None\n",
    "    start_index = 0\n",
    "    for index, node in enumerate(tagged):\n",
    "        tag = node[1]\n",
    "        if (tag == 'O' or tag != last_tag) and (start_index != index): # If end of block (All 'O' blocks are separated)\n",
    "            subset      = tagged[start_index:index]            # Get the block\n",
    "            tokens      = [pair[0].lower() for pair in subset] # Get the block lowercase word\n",
    "            token       = ' '.join(tokens)                     # Join the block in a single string\n",
    "            last_tag    = tag                                  \n",
    "            start_index = index\n",
    "            parsed.append(token)\n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its time to run both taggers and check the correlation obtained between the sentences. First using the *nltk.ne_chunk* function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " sentence0\n",
      "['the', 'bird', 'is', 'bathing', 'in', 'the', 'sink']\n",
      "['in', 'may', '2010', 'the', 'troops', 'attempted', 'to', 'invade', 'kabul']\n",
      "['john', 'said', 'he', 'is', 'considered', 'a', 'witness', 'but', 'not', 'a', 'suspect']\n",
      "['they', 'flew', 'out', 'of', 'the', 'nest', 'in', 'groups']\n",
      "['the', 'woman', 'is', 'playing', 'the', 'violin']\n",
      "['john', 'went', 'horse', 'back', 'riding', 'at', 'dawn', 'with', 'a', 'whole', 'group', 'of', 'friends']\n",
      "\n",
      " sentence1\n",
      "['birdie', 'is', 'washing', 'itself', 'in', 'the', 'water', 'basin']\n",
      "['the', 'us', 'army', 'invaded', 'kabul', 'on', 'may', '7th', 'last', 'year', '2010']\n",
      "['he', 'is', 'not', 'a', 'suspect', 'anymore', 'john', 'said']\n",
      "['they', 'flew', 'into', 'the', 'nest', 'together']\n",
      "['the', 'young', 'lady', 'enjoys', 'listening', 'to', 'the', 'guitar']\n",
      "['sunrise', 'at', 'dawn', 'is', 'a', 'magnificent', 'view', 'to', 'take', 'in', 'if', 'you', 'wake', 'up', 'early', 'enough', 'for', 'it']\n",
      "\n",
      "Similarities:\n",
      "        labels\n",
      "id1  0.272727\n",
      "id2  0.250000\n",
      "id3  0.636364\n",
      "id4  0.400000\n",
      "id5  0.090909\n",
      "id6  0.107143\n",
      "\n",
      "Pearson correlation index: 0.40498149435177305\n"
     ]
    }
   ],
   "source": [
    "def nltk_operation(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    taggs  = pos_tag(tokens)\n",
    "    nes    = ne_chunk(taggs, binary = True)\n",
    "    return nltk_parser(nes)\n",
    "\n",
    "analyzeResults(\n",
    "    preprocessing(deepcopy(trial_df), nltk_operation)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, it can be seen that there was no change in the tokenization of the sentences. Either *ne_chunk* is not powerfull enough to distinguish name entities in this context or the sentences have too few context to extract that information.\n",
    "\n",
    "In any case, the pearson correlation index and the values of the similarities is the same as the ones obtained in the session 2 using only Jaccard distances and word tokenization. \n",
    "\n",
    "Moreover, if the *ne_chunker* would have consider that, for example, ````the troops```` is a whole name entity, the Jaccard distance between the pair of sentences will be smaller, because the set is now smaller, so the similar items have more weight in the calculation. But the same effect would have been achieved with completely different sentences: an increase in similiraty. It can probably be safe to assume that the name entity parser alone is not enough to make a better correlation but instead a more complex method that uses the output of this one should be implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the CoreNLPParser.tag function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " sentence0\n",
      "['the', 'bird', 'is', 'bathing', 'in', 'the', 'sink']\n",
      "['in', 'may 2010', ',', 'the', 'troops', 'attempted', 'to', 'invade', 'kabul']\n",
      "['john', 'said', 'he', 'is', 'considered', 'a', 'witness', 'but', 'not', 'a', 'suspect']\n",
      "['they', 'flew', 'out', 'of', 'the', 'nest', 'in', 'groups']\n",
      "['the', 'woman', 'is', 'playing', 'the', 'violin']\n",
      "['john', 'went', 'horse', 'back', 'riding', 'at', 'dawn', 'with', 'a', 'whole', 'group', 'of', 'friends']\n",
      "\n",
      " sentence1\n",
      "['birdie', 'is', 'washing', 'itself', 'in', 'the', 'water', 'basin']\n",
      "['the', 'us', 'army', 'invaded', 'kabul', 'on', 'may 7th last year , 2010']\n",
      "['``', 'he', 'is', 'not', 'a', 'suspect', 'anymore', '.', \"''\", 'john', 'said']\n",
      "['they', 'flew', 'into', 'the', 'nest', 'together']\n",
      "['the', 'young', 'lady', 'enjoys', 'listening', 'to', 'the', 'guitar']\n",
      "['sunrise', 'at', 'dawn', 'is', 'a', 'magnificent', 'view', 'to', 'take', 'in', 'if', 'you', 'wake', 'up', 'early', 'enough', 'for', 'it']\n",
      "\n",
      "Similarities:\n",
      "        labels\n",
      "id1  0.272727\n",
      "id2  0.142857\n",
      "id3  0.500000\n",
      "id4  0.400000\n",
      "id5  0.090909\n",
      "id6  0.107143\n",
      "\n",
      "Pearson correlation index: 0.3429258002184723\n"
     ]
    }
   ],
   "source": [
    "def nltk_operation(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    nes    = parser.tag(tokens)\n",
    "    return nlp_parser(nes)\n",
    "\n",
    "analyzeResults(\n",
    "    preprocessing(deepcopy(trial_df), nltk_operation)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, it can be seen that some name entities where found (tagged as Dates):\n",
    "* ````may 2010````\n",
    "* ````may 7th last year , 2010````\n",
    "\n",
    "This surprisingly makes the similarity for the sentence with id2 worse (And a worse pearson correlation index is obtained). The cause for this is the decrease in the length of both sets while removing some of the matching words: may and 2010. Now, both these tokens will not match, decreasing the number of similar tokens in each set.\n",
    "\n",
    "A solution for this may be to accept two tokens as a coincidence when one of its words is the same in both (excluding stopwords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
