{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.metrics import jaccard_distance\n",
    "import csv\n",
    "from nltk import ne_chunk,pos_tag,word_tokenize\n",
    "from nltk.chunk import tree2conllstr\n",
    "from nltk.tree import Tree\n",
    "from nltk.parse import CoreNLPParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = CoreNLPParser(url='http://localhost:9000', tagtype='ner')\n",
    "# java -mx4g -cp C:\\stanford-corenlp-full-2018-10-05\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'bird', 'is', 'bathing', 'in', 'the', 'sink']\n",
      "['in', 'the', 'troops', 'attempted', 'to', 'invade', 'kabul']\n",
      "['john', 'said', 'he', 'is', 'considered', 'a', 'witness', 'but', 'not', 'a', 'suspect']\n",
      "['they', 'flew', 'out', 'of', 'the', 'nest', 'in', 'groups']\n",
      "['the', 'woman', 'is', 'playing', 'the', 'violin']\n",
      "['john', 'went', 'horse', 'back', 'riding', 'at', 'dawn', 'with', 'a', 'whole', 'group', 'of', 'friends']\n",
      "['birdie', 'is', 'washing', 'itself', 'in', 'the', 'water', 'basin']\n",
      "['the', 'us', 'army', 'invaded', 'kabul', 'on']\n",
      "['he', 'is', 'not', 'a', 'suspect', 'anymore', 'john', 'said']\n",
      "['they', 'flew', 'into', 'the', 'nest', 'together']\n",
      "['the', 'young', 'lady', 'enjoys', 'listening', 'to', 'the', 'guitar']\n",
      "['sunrise', 'at', 'dawn', 'is', 'a', 'magnificent', 'view', 'to', 'take', 'in', 'if', 'you', 'wake', 'up', 'early', 'enough', 'for', 'it']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence0</th>\n",
       "      <th>sentence1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id1</th>\n",
       "      <td>[the, bird, is, bathing, in, the, sink]</td>\n",
       "      <td>[birdie, is, washing, itself, in, the, water, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id2</th>\n",
       "      <td>[in, the, troops, attempted, to, invade, kabul]</td>\n",
       "      <td>[the, us, army, invaded, kabul, on]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id3</th>\n",
       "      <td>[john, said, he, is, considered, a, witness, b...</td>\n",
       "      <td>[he, is, not, a, suspect, anymore, john, said]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id4</th>\n",
       "      <td>[they, flew, out, of, the, nest, in, groups]</td>\n",
       "      <td>[they, flew, into, the, nest, together]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id5</th>\n",
       "      <td>[the, woman, is, playing, the, violin]</td>\n",
       "      <td>[the, young, lady, enjoys, listening, to, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id6</th>\n",
       "      <td>[john, went, horse, back, riding, at, dawn, wi...</td>\n",
       "      <td>[sunrise, at, dawn, is, a, magnificent, view, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence0  \\\n",
       "id1            [the, bird, is, bathing, in, the, sink]   \n",
       "id2    [in, the, troops, attempted, to, invade, kabul]   \n",
       "id3  [john, said, he, is, considered, a, witness, b...   \n",
       "id4       [they, flew, out, of, the, nest, in, groups]   \n",
       "id5             [the, woman, is, playing, the, violin]   \n",
       "id6  [john, went, horse, back, riding, at, dawn, wi...   \n",
       "\n",
       "                                             sentence1  \n",
       "id1  [birdie, is, washing, itself, in, the, water, ...  \n",
       "id2                [the, us, army, invaded, kabul, on]  \n",
       "id3     [he, is, not, a, suspect, anymore, john, said]  \n",
       "id4            [they, flew, into, the, nest, together]  \n",
       "id5  [the, young, lady, enjoys, listening, to, the,...  \n",
       "id6  [sunrise, at, dawn, is, a, magnificent, view, ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_path = 'data/trial/STS.input.txt'\n",
    "trial_gs_path = 'data/trial/STS.gs.txt'\n",
    "trial_df = pd.read_csv(trial_path, sep='\\t', lineterminator='\\n', names=['sentence0','sentence1'], header=None, quoting=csv.QUOTE_NONE)\n",
    "trial_gs = pd.read_csv(trial_gs_path, sep='\\t', lineterminator='\\n', names=['labels'], header=None, quoting=csv.QUOTE_NONE)\n",
    "\n",
    "def na_parser(tagged):\n",
    "    parsed     = []\n",
    "    last_tag   = None\n",
    "    start_index = 0\n",
    "    for index, node in enumerate(tagged):\n",
    "        tag = node[1]\n",
    "        if (tag == 'O' or tag != last_tag) and (start_index != index):\n",
    "            token = ' '.join([pair[0].lower() for pair in tagged[start_index:index]])\n",
    "            if token.isalnum():\n",
    "                parsed.append(token)\n",
    "            last_tag = tag\n",
    "            start_index = index\n",
    "    return parsed\n",
    "\n",
    "\n",
    "def preprocessing(data):\n",
    "    # To see the effect of the desambiguation we do a preprocess only with it. Generaly we will use a more complete \n",
    "    # preprocessing function. \n",
    "    data = data.fillna('')\n",
    "    first = lambda x: [a[0] for a in x]\n",
    "    for column in data.columns:\n",
    "        # words to lower\n",
    "        #data[column] = data[column].str.lower()\n",
    "        # desambiguate \n",
    "        data[column] = data[column].apply(word_tokenize)\n",
    "        data[column] = data[column].apply(parser.tag)\n",
    "        data[column] = data[column].apply(na_parser)\n",
    "        data[column].apply(print)\n",
    "    return data\n",
    "\n",
    "trial_df = preprocessing(trial_df)\n",
    "trial_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_simmilarity(df):\n",
    "    guess = pd.DataFrame()\n",
    "    for i in df.index:\n",
    "        guess.loc[i,'labels'] = 1. - jaccard_distance(set(df.loc[i,'sentence0']), set(df.loc[i,'sentence1']))\n",
    "    return guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       labels\n",
      "id1  0.272727\n",
      "id2  0.181818\n",
      "id3  0.636364\n",
      "id4  0.400000\n",
      "id5  0.090909\n",
      "id6  0.107143\n"
     ]
    }
   ],
   "source": [
    "guess_lex = lexical_simmilarity(trial_df)\n",
    "print(guess_lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.34327956222578704\n"
     ]
    }
   ],
   "source": [
    "print(pearsonr(trial_gs['labels'], guess_lex['labels'])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are even worse than the first ones and i don't know why. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
