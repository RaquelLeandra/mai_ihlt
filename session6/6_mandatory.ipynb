{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mandatory - Session 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from nltk.wsd import lesk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.metrics import jaccard_distance\n",
    "from scipy.stats import pearsonr\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load the datasets with panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence0</th>\n",
       "      <th>sentence1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id1</th>\n",
       "      <td>The bird is bathing in the sink.</td>\n",
       "      <td>Birdie is washing itself in the water basin.\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id2</th>\n",
       "      <td>In May 2010, the troops attempted to invade Ka...</td>\n",
       "      <td>The US army invaded Kabul on May 7th last year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id3</th>\n",
       "      <td>John said he is considered a witness but not a...</td>\n",
       "      <td>\"He is not a suspect anymore.\" John said.\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id4</th>\n",
       "      <td>They flew out of the nest in groups.</td>\n",
       "      <td>They flew into the nest together.\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id5</th>\n",
       "      <td>The woman is playing the violin.</td>\n",
       "      <td>The young lady enjoys listening to the guitar.\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id6</th>\n",
       "      <td>John went horse back riding at dawn with a who...</td>\n",
       "      <td>Sunrise at dawn is a magnificent view to take ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence0  \\\n",
       "id1                   The bird is bathing in the sink.   \n",
       "id2  In May 2010, the troops attempted to invade Ka...   \n",
       "id3  John said he is considered a witness but not a...   \n",
       "id4               They flew out of the nest in groups.   \n",
       "id5                   The woman is playing the violin.   \n",
       "id6  John went horse back riding at dawn with a who...   \n",
       "\n",
       "                                             sentence1  \n",
       "id1     Birdie is washing itself in the water basin.\\r  \n",
       "id2  The US army invaded Kabul on May 7th last year...  \n",
       "id3        \"He is not a suspect anymore.\" John said.\\r  \n",
       "id4                They flew into the nest together.\\r  \n",
       "id5   The young lady enjoys listening to the guitar.\\r  \n",
       "id6  Sunrise at dawn is a magnificent view to take ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_path    = 'trial/STS.input.txt'\n",
    "trial_gs_path = 'trial/STS.gs.txt'\n",
    "trial_df      = pd.read_csv(trial_path, sep='\\t', lineterminator='\\n', names=['sentence0','sentence1'], header=None, quoting=csv.QUOTE_NONE)\n",
    "trial_gs      = pd.read_csv(trial_gs_path, sep='\\t', lineterminator='\\n', names=['labels'], header=None, quoting=csv.QUOTE_NONE).iloc[::-1]\n",
    "trial_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the functions to calculate using lesk the meaning of words in a context. If no meaning is found for a word, the token is keep as it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lesk_to_text(senten):\n",
    "    ''' Convert a sentence to a list of tokens with meanings. '''\n",
    "    tokens   = word_tokenize(senten)\n",
    "    tagged   = pos_tag(tokens)\n",
    "    semantic = []\n",
    "    \n",
    "    for idx, token in enumerate(tokens):             # For each word\n",
    "        context = [i for i in tokens if i != token]  # Context for the word ({S} - {word})\n",
    "        tag     = tagged[idx][1][0].lower()          # POS tag for the word\n",
    "        synset  = lesk(context, token.lower(), tag)  # Lesk algorithm => Synset        \n",
    "        if synset:\n",
    "            semantic.append(str(synset).replace('Synset(\\'', '').replace('\\')', ''))  # If a meaning was found\n",
    "        else:\n",
    "            semantic.append(token.lower()) # If no meaning was found\n",
    "\n",
    "    return semantic\n",
    "\n",
    "def preprocessing(data):\n",
    "    ''' Preprocess all sentences to infer their meanings. Generaly a more complete preprocessing function will be used. '''\n",
    "    data = data.fillna('')\n",
    "    for column in data.columns:\n",
    "        # words to lower\n",
    "        data[column] = data[column].str.lower()\n",
    "        # desambiguate \n",
    "        data[column] = data[column].apply(apply_lesk_to_text)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the preprocessing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence0</th>\n",
       "      <th>sentence1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id1</th>\n",
       "      <td>[the, bird.n.02, be.v.12, bathe.v.01, in, the,...</td>\n",
       "      <td>[shuttlecock.n.01, be.v.12, wash.v.09, itself,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id2</th>\n",
       "      <td>[in, may, 2010, ,, the, troop.n.02, undertake....</td>\n",
       "      <td>[the, us, army, invaded, kabul.n.01, on, may, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id3</th>\n",
       "      <td>[whoremaster.n.01, suppose.v.01, he, embody.v....</td>\n",
       "      <td>[``, he, embody.v.02, not.r.01, a, defendant.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id4</th>\n",
       "      <td>[they, fly.v.12, out, of, the, nest, in, group...</td>\n",
       "      <td>[they, fly.v.10, into, the, nest, together.r.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id5</th>\n",
       "      <td>[the, woman.n.02, be.v.05, play.v.35, the, vio...</td>\n",
       "      <td>[the, young, lady.n.03, love.v.02, heed.v.01, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id6</th>\n",
       "      <td>[toilet.n.01, plump.v.04, knight.n.02, back.r....</td>\n",
       "      <td>[sunrise.n.03, at, dawn.n.03, be.v.12, a, magn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence0  \\\n",
       "id1  [the, bird.n.02, be.v.12, bathe.v.01, in, the,...   \n",
       "id2  [in, may, 2010, ,, the, troop.n.02, undertake....   \n",
       "id3  [whoremaster.n.01, suppose.v.01, he, embody.v....   \n",
       "id4  [they, fly.v.12, out, of, the, nest, in, group...   \n",
       "id5  [the, woman.n.02, be.v.05, play.v.35, the, vio...   \n",
       "id6  [toilet.n.01, plump.v.04, knight.n.02, back.r....   \n",
       "\n",
       "                                             sentence1  \n",
       "id1  [shuttlecock.n.01, be.v.12, wash.v.09, itself,...  \n",
       "id2  [the, us, army, invaded, kabul.n.01, on, may, ...  \n",
       "id3  [``, he, embody.v.02, not.r.01, a, defendant.n...  \n",
       "id4  [they, fly.v.10, into, the, nest, together.r.0...  \n",
       "id5  [the, young, lady.n.03, love.v.02, heed.v.01, ...  \n",
       "id6  [sunrise.n.03, at, dawn.n.03, be.v.12, a, magn...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_df = preprocessing(trial_df)\n",
    "trial_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, calculate the similarities using the jaccard distance..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id1</th>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id2</th>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id3</th>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id4</th>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id5</th>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id6</th>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels\n",
       "id1  0.333333\n",
       "id2  0.333333\n",
       "id3  0.571429\n",
       "id4  0.333333\n",
       "id5  0.166667\n",
       "id6  0.100000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lexical_simmilarity(df):\n",
    "    guess = pd.DataFrame()\n",
    "    for i in df.index:\n",
    "        guess.loc[i,'labels'] = 1 - jaccard_distance(set(df.loc[i,'sentence0']), set(df.loc[i,'sentence1']))\n",
    "    return guess\n",
    "\n",
    "guess_lex = lexical_simmilarity(trial_df)\n",
    "guess_lex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6206712050540985\n"
     ]
    }
   ],
   "source": [
    "print(pearsonr(trial_gs['labels'], guess_lex['labels'])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On session 2, we compared the sentences practically as given and we obtained a correlation of 0.51. \n",
    "- On session 3, we performed a lemmatization of the sentences and obtained a correlation of 0.57. \n",
    "- On this session we performed a desambiguation and we have obtained a coefficient of 0.62. This is an improvement over the lemmatization.\n",
    "\n",
    "As commented on previous sessions, \n",
    "\n",
    "> This value is bigger than 0.5, this means that there is some correlation between the two arrays, so this may make a good algorithm to measure semantic similarity between sentences (Lesk + Jaccard). But it is still not a very good value. Using hypernyms and hyponyms will probably improve the result.  \n",
    "\n",
    "> The _poor_ performance may be a consecuence of the definition of Jaccard distance. This definition is fully based on set theory and does not take into account the semantic relationship between words.\n",
    "\n",
    "These facts explain why the current results are better than the ones on the other sessions; The desambiguation values returned by lesk should be related to the sense of the words, this implies than sometimes this value will be the same on the two sentences, making greater the simmilarity between them.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
