{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from nltk.wsd import lesk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.metrics import jaccard_distance\n",
    "from scipy.stats import pearsonr\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 2) (6, 1)\n"
     ]
    }
   ],
   "source": [
    "trial_path = 'trial/STS.input.txt'\n",
    "trial_gs_path = 'trial/STS.gs.txt'\n",
    "trial_df = pd.read_csv(trial_path, sep='\\t', lineterminator='\\n', names=['sentence0','sentence1'], header=None, quoting=csv.QUOTE_NONE)\n",
    "trial_gs = pd.read_csv(trial_gs_path, sep='\\t', lineterminator='\\n', names=['labels'], header=None, quoting=csv.QUOTE_NONE)\n",
    "print(trial_df.shape, trial_gs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morphy_tag(nltk_tag):\n",
    "\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def apply_lesk_to_text(text):\n",
    "    tokenized_text = word_tokenize(text)\n",
    "    list_tags = pos_tag(tokenized_text)\n",
    "    tags = {w:morphy_tag(tag) for w,tag in list_tags}\n",
    "    lesk_text = [lesk(tokenized_text, word,tags[word]) if tags[word] else word for word in tokenized_text]\n",
    "    lesk_text_str = []\n",
    "    for word in lesk_text:\n",
    "        try: \n",
    "            w =  word.name().split('.')[0]\n",
    "        except: \n",
    "            w = word\n",
    "        lesk_text_str.append(w)\n",
    "    \n",
    "    return lesk_text_str\n",
    "\n",
    "def preprocessing(data):\n",
    "    # To see the effect of the desambiguation we do a preprocess only with it. Generaly we will use a more complete \n",
    "    # preprocessing function. \n",
    "    data = data.fillna('')\n",
    "    for column in data.columns:\n",
    "        # words to lower\n",
    "        data[column] = data[column].str.lower()\n",
    "        # desambiguate \n",
    "        data[column] = data[column].apply(apply_lesk_to_text)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence0</th>\n",
       "      <th>sentence1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id1</th>\n",
       "      <td>[the, bird, be, bathe, in, the, sinkhole, .]</td>\n",
       "      <td>[shuttlecock, be, wash, itself, in, the, body_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id2</th>\n",
       "      <td>[in, may, 2010, ,, the, troop, undertake, to, ...</td>\n",
       "      <td>[the, us, None, None, kabul, on, may, 7th, las...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id3</th>\n",
       "      <td>[whoremaster, suppose, he, embody, view, a, wi...</td>\n",
       "      <td>[``, he, embody, not, a, defendant, anymore, ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id4</th>\n",
       "      <td>[they, fly, out, of, the, None, in, group, .]</td>\n",
       "      <td>[they, fly, into, the, None, together, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id5</th>\n",
       "      <td>[the, woman, be, play, the, violin, .]</td>\n",
       "      <td>[the, young, lady, love, heed, to, the, guitar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id6</th>\n",
       "      <td>[toilet, plump, knight, back, ride, at, dawn, ...</td>\n",
       "      <td>[sunrise, at, dawn, be, a, None, view, to, tak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence0  \\\n",
       "id1       [the, bird, be, bathe, in, the, sinkhole, .]   \n",
       "id2  [in, may, 2010, ,, the, troop, undertake, to, ...   \n",
       "id3  [whoremaster, suppose, he, embody, view, a, wi...   \n",
       "id4      [they, fly, out, of, the, None, in, group, .]   \n",
       "id5             [the, woman, be, play, the, violin, .]   \n",
       "id6  [toilet, plump, knight, back, ride, at, dawn, ...   \n",
       "\n",
       "                                             sentence1  \n",
       "id1  [shuttlecock, be, wash, itself, in, the, body_...  \n",
       "id2  [the, us, None, None, kabul, on, may, 7th, las...  \n",
       "id3  [``, he, embody, not, a, defendant, anymore, ....  \n",
       "id4          [they, fly, into, the, None, together, .]  \n",
       "id5  [the, young, lady, love, heed, to, the, guitar...  \n",
       "id6  [sunrise, at, dawn, be, a, None, view, to, tak...  "
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_df = preprocessing(trial_df)\n",
    "trial_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id1</th>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id2</th>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id3</th>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id4</th>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id5</th>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels\n",
       "id1  0.666667\n",
       "id2  0.647059\n",
       "id3  0.428571\n",
       "id4  0.545455\n",
       "id5  0.833333"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lexical_simmilarity(df):\n",
    "    guess = pd.DataFrame()\n",
    "    for i in df.index:\n",
    "        guess.loc[i,'labels'] = 1 - jaccard_distance(set(df.loc[i,'sentence0']), set(df.loc[i,'sentence1']))\n",
    "    return guess\n",
    "\n",
    "guess_lex = lexical_simmilarity(trial_df)\n",
    "guess_lex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5323734100639426\n"
     ]
    }
   ],
   "source": [
    "print(pearsonr(trial_gs['labels'], guess_lex['labels'])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain a value lower than expected. \n",
    "On session 2, we compared the sentences practically as given and we obtained a correlation of 0.51. \n",
    "On session 3, we performed a lemmatization of the sentences and obtained a correlation of 0.57. \n",
    "On this session we performed a desambiguation and we have obtained a coefficient of 0.53. This value is a little better than the one on session 2 but worse than the one on the lemmatization. \n",
    "\n",
    "As commented on previous sessions, \n",
    "\n",
    "> This time we haven't processed the gold standar values, so we are comparing a distance array with a simmilarity one, so we obtain a negative correlation. \n",
    "\n",
    "> This value is a little bigger than 0.5, this means that there is little correlation between the two arrays, so probably the Jaccard distance isn't the best way to measure the semantic similarity between this sentences. \n",
    "\n",
    "> These results are due to the definition of Jaccard distance. This definition is fully based on set theory and does not take into account the semantic relationship between words (like synonymity).\n",
    "\n",
    "\n",
    "This facts explain why the current results are better than the ones on session 2; The desambiguation values returned by lesk should be related to the sense of the words, this implies than sometimes this value will be the same on the two sentences, making greater the simmilarity between them. \n",
    "\n",
    "On the other hand we had better results on session 3, this is because:\n",
    "1. The Jaccard distance deffinition; With Jaccard, have more simmilarity means have more common words between the two sentences, this implies than Jaccard doesn't treats two morphological variation of a word as the same word. If we use a lemmatization of the word we avoid this problem, but no with the desambiguation. That's the first reason why the results on session 3 where better. \n",
    "2. Use \"corpus\" too little to desambiguate; The lesk function compares the corpus given with the deffinition of the word. If the corpus is too little is probably that it won't find the correct sense of the word. One example of this is that it changes \"Birdie\" to \"shuttlecock\" instead of returning \"bird\". \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
